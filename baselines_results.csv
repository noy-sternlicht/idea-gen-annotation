example_id,annotator,context,gold,baseline,suggestion,is_ill_defined,knowledge_level,k,rank,normalized_rank
1-42304_544e6956-8092-4102-8996-c9d4a7500a75,noy.sternlicht@mail.huji.ac.il,"The performance of large language models (LLMs) can be significantly enhanced through effective prompt optimization, yet existing methods may not fully leverage the potential of LLMs as prompt optimizers. There is a need for improved strategies that systematically analyze and refine task prompts to achieve better outcomes in various benchmarks.",gradient-based model optimizers,gpt-4o,genetic algorithms,False,3,1,2,1.0
1-42304_544e6956-8092-4102-8996-c9d4a7500a75,noy.sternlicht@mail.huji.ac.il,"The performance of large language models (LLMs) can be significantly enhanced through effective prompt optimization, yet existing methods may not fully leverage the potential of LLMs as prompt optimizers. There is a need for improved strategies that systematically analyze and refine task prompts to achieve better outcomes in various benchmarks.",gradient-based model optimizers,ours,the concept of prompt tuning,False,3,1,5,2.5
1-42304_544e6956-8092-4102-8996-c9d4a7500a75,noy.sternlicht@mail.huji.ac.il,"The performance of large language models (LLMs) can be significantly enhanced through effective prompt optimization, yet existing methods may not fully leverage the potential of LLMs as prompt optimizers. There is a need for improved strategies that systematically analyze and refine task prompts to achieve better outcomes in various benchmarks.",gradient-based model optimizers,mpnet_zero,prompt-engineering-based large language models,False,3,1,4,2.0
1-42304_544e6956-8092-4102-8996-c9d4a7500a75,noy.sternlicht@mail.huji.ac.il,"The performance of large language models (LLMs) can be significantly enhanced through effective prompt optimization, yet existing methods may not fully leverage the potential of LLMs as prompt optimizers. There is a need for improved strategies that systematically analyze and refine task prompts to achieve better outcomes in various benchmarks.",gradient-based model optimizers,random,Learning effective representations from raw data,False,3,1,6,3.0
1-42304_544e6956-8092-4102-8996-c9d4a7500a75,noy.sternlicht@mail.huji.ac.il,"The performance of large language models (LLMs) can be significantly enhanced through effective prompt optimization, yet existing methods may not fully leverage the potential of LLMs as prompt optimizers. There is a need for improved strategies that systematically analyze and refine task prompts to achieve better outcomes in various benchmarks.",gradient-based model optimizers,positive,gradient-based model optimizers,False,3,1,1,0.5
1-42304_544e6956-8092-4102-8996-c9d4a7500a75,noy.sternlicht@mail.huji.ac.il,"The performance of large language models (LLMs) can be significantly enhanced through effective prompt optimization, yet existing methods may not fully leverage the potential of LLMs as prompt optimizers. There is a need for improved strategies that systematically analyze and refine task prompts to achieve better outcomes in various benchmarks.",gradient-based model optimizers,sciIE,prompt-engineering-based large language models (LLMs),False,3,1,3,1.5
1-30868_92eac6d1-ca2e-40a8-9b84-255e46cb5372,noy.sternlicht@mail.huji.ac.il,"Automated Long Answer Grading (ALAG) presents unique challenges due to the complexity and multifaceted nature of fact-based long answers, which differ significantly from shorter answer formats. The traditional score-based approaches fail to capture the nuances of student responses, highlighting the need for a more effective method to evaluate long answers in educational settings.",a rubric entailment problem,positive,a rubric entailment problem,False,4,1,2,1.3333333333333333
1-30868_92eac6d1-ca2e-40a8-9b84-255e46cb5372,noy.sternlicht@mail.huji.ac.il,"Automated Long Answer Grading (ALAG) presents unique challenges due to the complexity and multifaceted nature of fact-based long answers, which differ significantly from shorter answer formats. The traditional score-based approaches fail to capture the nuances of student responses, highlighting the need for a more effective method to evaluate long answers in educational settings.",a rubric entailment problem,random,the flexibility of the Choquet integral,False,4,1,6,4.0
1-30868_92eac6d1-ca2e-40a8-9b84-255e46cb5372,noy.sternlicht@mail.huji.ac.il,"Automated Long Answer Grading (ALAG) presents unique challenges due to the complexity and multifaceted nature of fact-based long answers, which differ significantly from shorter answer formats. The traditional score-based approaches fail to capture the nuances of student responses, highlighting the need for a more effective method to evaluate long answers in educational settings.",a rubric entailment problem,sciIE,Automated Long Answer Grading (ALAG),False,4,1,4,2.6666666666666665
1-30868_92eac6d1-ca2e-40a8-9b84-255e46cb5372,noy.sternlicht@mail.huji.ac.il,"Automated Long Answer Grading (ALAG) presents unique challenges due to the complexity and multifaceted nature of fact-based long answers, which differ significantly from shorter answer formats. The traditional score-based approaches fail to capture the nuances of student responses, highlighting the need for a more effective method to evaluate long answers in educational settings.",a rubric entailment problem,gpt-4o,natural language processing techniques,False,4,1,5,3.333333333333333
1-30868_92eac6d1-ca2e-40a8-9b84-255e46cb5372,noy.sternlicht@mail.huji.ac.il,"Automated Long Answer Grading (ALAG) presents unique challenges due to the complexity and multifaceted nature of fact-based long answers, which differ significantly from shorter answer formats. The traditional score-based approaches fail to capture the nuances of student responses, highlighting the need for a more effective method to evaluate long answers in educational settings.",a rubric entailment problem,ours,evidence-centered design in educational assessments,False,4,1,1,0.6666666666666666
1-30868_92eac6d1-ca2e-40a8-9b84-255e46cb5372,noy.sternlicht@mail.huji.ac.il,"Automated Long Answer Grading (ALAG) presents unique challenges due to the complexity and multifaceted nature of fact-based long answers, which differ significantly from shorter answer formats. The traditional score-based approaches fail to capture the nuances of student responses, highlighting the need for a more effective method to evaluate long answers in educational settings.",a rubric entailment problem,mpnet_zero,automated essay scoring,False,4,1,3,2.0
1-37730_6df467e6-c5d7-4a07-9565-99147fcadcdb,noy.sternlicht@mail.huji.ac.il,"Existing methods for temporal relation extraction struggle with limited and unevenly distributed annotated data, highlighting a need for more effective approaches to understand task requests in crowdsourcing systems. This gap in research necessitates innovative solutions that can leverage abundant global knowledge to enhance performance in this area.",the abundant global knowledge stored within pre-trained language models,sciIE,relation extraction,False,4,1,6,4.0
1-37730_6df467e6-c5d7-4a07-9565-99147fcadcdb,noy.sternlicht@mail.huji.ac.il,"Existing methods for temporal relation extraction struggle with limited and unevenly distributed annotated data, highlighting a need for more effective approaches to understand task requests in crowdsourcing systems. This gap in research necessitates innovative solutions that can leverage abundant global knowledge to enhance performance in this area.",the abundant global knowledge stored within pre-trained language models,gpt-4o,transfer learning,False,4,1,3,2.0
1-37730_6df467e6-c5d7-4a07-9565-99147fcadcdb,noy.sternlicht@mail.huji.ac.il,"Existing methods for temporal relation extraction struggle with limited and unevenly distributed annotated data, highlighting a need for more effective approaches to understand task requests in crowdsourcing systems. This gap in research necessitates innovative solutions that can leverage abundant global knowledge to enhance performance in this area.",the abundant global knowledge stored within pre-trained language models,positive,the abundant global knowledge stored within pre-trained language models,False,4,1,1,0.6666666666666666
1-37730_6df467e6-c5d7-4a07-9565-99147fcadcdb,noy.sternlicht@mail.huji.ac.il,"Existing methods for temporal relation extraction struggle with limited and unevenly distributed annotated data, highlighting a need for more effective approaches to understand task requests in crowdsourcing systems. This gap in research necessitates innovative solutions that can leverage abundant global knowledge to enhance performance in this area.",the abundant global knowledge stored within pre-trained language models,mpnet_zero,Relation extraction models,False,4,1,5,3.333333333333333
1-37730_6df467e6-c5d7-4a07-9565-99147fcadcdb,noy.sternlicht@mail.huji.ac.il,"Existing methods for temporal relation extraction struggle with limited and unevenly distributed annotated data, highlighting a need for more effective approaches to understand task requests in crowdsourcing systems. This gap in research necessitates innovative solutions that can leverage abundant global knowledge to enhance performance in this area.",the abundant global knowledge stored within pre-trained language models,ours,Question answering over heterogeneous data,False,4,1,2,1.3333333333333333
1-37730_6df467e6-c5d7-4a07-9565-99147fcadcdb,noy.sternlicht@mail.huji.ac.il,"Existing methods for temporal relation extraction struggle with limited and unevenly distributed annotated data, highlighting a need for more effective approaches to understand task requests in crowdsourcing systems. This gap in research necessitates innovative solutions that can leverage abundant global knowledge to enhance performance in this area.",the abundant global knowledge stored within pre-trained language models,random,a supervised contrastive loss,False,4,1,4,2.6666666666666665
1-399_4303bb53-050b-41da-bdbd-0abe03f154ee,noy.sternlicht@mail.huji.ac.il,"The trustworthiness of retrieval-augmented language models is compromised by hallucinations, primarily due to the conflict between contextual and parametric knowledge. There is a need to align these models to respond based solely on external evidence, minimizing the influence of parametric knowledge to enhance their reliability in real-world applications.",aligning language models with human preference,positive,aligning language models with human preference,False,4,1,5,3.333333333333333
1-399_4303bb53-050b-41da-bdbd-0abe03f154ee,noy.sternlicht@mail.huji.ac.il,"The trustworthiness of retrieval-augmented language models is compromised by hallucinations, primarily due to the conflict between contextual and parametric knowledge. There is a need to align these models to respond based solely on external evidence, minimizing the influence of parametric knowledge to enhance their reliability in real-world applications.",aligning language models with human preference,ours,the generator-verifier approach in Large Language Models,False,4,1,1,0.6666666666666666
1-399_4303bb53-050b-41da-bdbd-0abe03f154ee,noy.sternlicht@mail.huji.ac.il,"The trustworthiness of retrieval-augmented language models is compromised by hallucinations, primarily due to the conflict between contextual and parametric knowledge. There is a need to align these models to respond based solely on external evidence, minimizing the influence of parametric knowledge to enhance their reliability in real-world applications.",aligning language models with human preference,mpnet_zero,improve the robustness and contextual awareness of Large Language Models,False,4,1,3,2.0
1-399_4303bb53-050b-41da-bdbd-0abe03f154ee,noy.sternlicht@mail.huji.ac.il,"The trustworthiness of retrieval-augmented language models is compromised by hallucinations, primarily due to the conflict between contextual and parametric knowledge. There is a need to align these models to respond based solely on external evidence, minimizing the influence of parametric knowledge to enhance their reliability in real-world applications.",aligning language models with human preference,sciIE,retrieval-augmented language models,False,4,1,4,2.6666666666666665
1-399_4303bb53-050b-41da-bdbd-0abe03f154ee,noy.sternlicht@mail.huji.ac.il,"The trustworthiness of retrieval-augmented language models is compromised by hallucinations, primarily due to the conflict between contextual and parametric knowledge. There is a need to align these models to respond based solely on external evidence, minimizing the influence of parametric knowledge to enhance their reliability in real-world applications.",aligning language models with human preference,gpt-4o,fact-checking systems,False,4,1,2,1.3333333333333333
1-399_4303bb53-050b-41da-bdbd-0abe03f154ee,noy.sternlicht@mail.huji.ac.il,"The trustworthiness of retrieval-augmented language models is compromised by hallucinations, primarily due to the conflict between contextual and parametric knowledge. There is a need to align these models to respond based solely on external evidence, minimizing the influence of parametric knowledge to enhance their reliability in real-world applications.",aligning language models with human preference,random,a non-linear motion prior in the form of pixel-level trajectories,False,4,1,6,4.0
1-23261_dcdf3bfd-5fb5-4416-bf14-0992a328cd59,noy.sternlicht@mail.huji.ac.il,"Modern Large Language Models (LLMs) exhibit a performance gap in basic tasks like relation and event extraction, primarily due to the imprecision of existing evaluation metrics and the incompleteness of evaluation benchmarks caused by restrictive human annotation schemas. These issues lead to an underestimation of LLM performances and highlight the need for improved evaluation methods that can better assess semantic consistency and address benchmark limitations.",the principles in subjective question correction,gpt-4o,human cognitive evaluation,False,4,1,3,2.0
1-23261_dcdf3bfd-5fb5-4416-bf14-0992a328cd59,noy.sternlicht@mail.huji.ac.il,"Modern Large Language Models (LLMs) exhibit a performance gap in basic tasks like relation and event extraction, primarily due to the imprecision of existing evaluation metrics and the incompleteness of evaluation benchmarks caused by restrictive human annotation schemas. These issues lead to an underestimation of LLM performances and highlight the need for improved evaluation methods that can better assess semantic consistency and address benchmark limitations.",the principles in subjective question correction,mpnet_zero,the success of large language models in NLP,False,4,1,1,0.6666666666666666
1-23261_dcdf3bfd-5fb5-4416-bf14-0992a328cd59,noy.sternlicht@mail.huji.ac.il,"Modern Large Language Models (LLMs) exhibit a performance gap in basic tasks like relation and event extraction, primarily due to the imprecision of existing evaluation metrics and the incompleteness of evaluation benchmarks caused by restrictive human annotation schemas. These issues lead to an underestimation of LLM performances and highlight the need for improved evaluation methods that can better assess semantic consistency and address benchmark limitations.",the principles in subjective question correction,sciIE,fine-tuned large language models (LLMs),False,4,1,2,1.3333333333333333
1-23261_dcdf3bfd-5fb5-4416-bf14-0992a328cd59,noy.sternlicht@mail.huji.ac.il,"Modern Large Language Models (LLMs) exhibit a performance gap in basic tasks like relation and event extraction, primarily due to the imprecision of existing evaluation metrics and the incompleteness of evaluation benchmarks caused by restrictive human annotation schemas. These issues lead to an underestimation of LLM performances and highlight the need for improved evaluation methods that can better assess semantic consistency and address benchmark limitations.",the principles in subjective question correction,positive,the principles in subjective question correction,False,4,1,6,4.0
1-23261_dcdf3bfd-5fb5-4416-bf14-0992a328cd59,noy.sternlicht@mail.huji.ac.il,"Modern Large Language Models (LLMs) exhibit a performance gap in basic tasks like relation and event extraction, primarily due to the imprecision of existing evaluation metrics and the incompleteness of evaluation benchmarks caused by restrictive human annotation schemas. These issues lead to an underestimation of LLM performances and highlight the need for improved evaluation methods that can better assess semantic consistency and address benchmark limitations.",the principles in subjective question correction,ours,human evaluation,False,4,1,4,2.6666666666666665
1-23261_dcdf3bfd-5fb5-4416-bf14-0992a328cd59,noy.sternlicht@mail.huji.ac.il,"Modern Large Language Models (LLMs) exhibit a performance gap in basic tasks like relation and event extraction, primarily due to the imprecision of existing evaluation metrics and the incompleteness of evaluation benchmarks caused by restrictive human annotation schemas. These issues lead to an underestimation of LLM performances and highlight the need for improved evaluation methods that can better assess semantic consistency and address benchmark limitations.",the principles in subjective question correction,random,human flexibility and reasoning,False,4,1,5,3.333333333333333
1-41549_fe8b430d-566c-4f49-b4d5-49035a791a6d,noy.sternlicht@mail.huji.ac.il,"The evaluation of large language models (LLMs) for clinical applications is critical to ensure their safe and reliable use, particularly in mitigating potential risks such as hallucinations. Current evaluation methods are heavily reliant on labor-intensive human participation, highlighting the need for more efficient and automated approaches to assess LLMs' capabilities in medical diagnosis and treatment.",professional clinical practice pathways,gpt-4o,simulation-based testing frameworks,False,2,1,2,0.6666666666666666
1-41549_fe8b430d-566c-4f49-b4d5-49035a791a6d,noy.sternlicht@mail.huji.ac.il,"The evaluation of large language models (LLMs) for clinical applications is critical to ensure their safe and reliable use, particularly in mitigating potential risks such as hallucinations. Current evaluation methods are heavily reliant on labor-intensive human participation, highlighting the need for more efficient and automated approaches to assess LLMs' capabilities in medical diagnosis and treatment.",professional clinical practice pathways,mpnet_zero,consulting a large language model and medical experts,False,2,1,3,1.0
1-41549_fe8b430d-566c-4f49-b4d5-49035a791a6d,noy.sternlicht@mail.huji.ac.il,"The evaluation of large language models (LLMs) for clinical applications is critical to ensure their safe and reliable use, particularly in mitigating potential risks such as hallucinations. Current evaluation methods are heavily reliant on labor-intensive human participation, highlighting the need for more efficient and automated approaches to assess LLMs' capabilities in medical diagnosis and treatment.",professional clinical practice pathways,sciIE,complexity of medical language,False,2,1,6,2.0
1-41549_fe8b430d-566c-4f49-b4d5-49035a791a6d,noy.sternlicht@mail.huji.ac.il,"The evaluation of large language models (LLMs) for clinical applications is critical to ensure their safe and reliable use, particularly in mitigating potential risks such as hallucinations. Current evaluation methods are heavily reliant on labor-intensive human participation, highlighting the need for more efficient and automated approaches to assess LLMs' capabilities in medical diagnosis and treatment.",professional clinical practice pathways,positive,professional clinical practice pathways,False,2,1,1,0.3333333333333333
1-41549_fe8b430d-566c-4f49-b4d5-49035a791a6d,noy.sternlicht@mail.huji.ac.il,"The evaluation of large language models (LLMs) for clinical applications is critical to ensure their safe and reliable use, particularly in mitigating potential risks such as hallucinations. Current evaluation methods are heavily reliant on labor-intensive human participation, highlighting the need for more efficient and automated approaches to assess LLMs' capabilities in medical diagnosis and treatment.",professional clinical practice pathways,random,task-specific NLP models,False,2,1,5,1.6666666666666665
1-41549_fe8b430d-566c-4f49-b4d5-49035a791a6d,noy.sternlicht@mail.huji.ac.il,"The evaluation of large language models (LLMs) for clinical applications is critical to ensure their safe and reliable use, particularly in mitigating potential risks such as hallucinations. Current evaluation methods are heavily reliant on labor-intensive human participation, highlighting the need for more efficient and automated approaches to assess LLMs' capabilities in medical diagnosis and treatment.",professional clinical practice pathways,ours,"the widely-adopted ""needle-in-a-haystack"" (needle-in-a-haystack"") evaluation",False,2,1,4,1.3333333333333333
1-4330_cca3fb24-9267-4e27-941e-55040f509ca5,noy.sternlicht@mail.huji.ac.il,"There is a growing concern about distinguishing between LLM-generated and human-written texts to prevent misuse, such as the dissemination of misleading information and academic dishonesty. Previous research has primarily focused on classifying text as either entirely human-written or LLM-generated, neglecting the detection of mixed texts that contain both types of content.",a token classification problem,ours,recent works on machine-generated text detection,False,4,1,3,2.0
1-4330_cca3fb24-9267-4e27-941e-55040f509ca5,noy.sternlicht@mail.huji.ac.il,"There is a growing concern about distinguishing between LLM-generated and human-written texts to prevent misuse, such as the dissemination of misleading information and academic dishonesty. Previous research has primarily focused on classifying text as either entirely human-written or LLM-generated, neglecting the detection of mixed texts that contain both types of content.",a token classification problem,gpt-4o,stylometry techniques,False,4,1,1,0.6666666666666666
1-4330_cca3fb24-9267-4e27-941e-55040f509ca5,noy.sternlicht@mail.huji.ac.il,"There is a growing concern about distinguishing between LLM-generated and human-written texts to prevent misuse, such as the dissemination of misleading information and academic dishonesty. Previous research has primarily focused on classifying text as either entirely human-written or LLM-generated, neglecting the detection of mixed texts that contain both types of content.",a token classification problem,random,Adversarial attacks against language models(LMs),False,4,1,4,2.6666666666666665
1-4330_cca3fb24-9267-4e27-941e-55040f509ca5,noy.sternlicht@mail.huji.ac.il,"There is a growing concern about distinguishing between LLM-generated and human-written texts to prevent misuse, such as the dissemination of misleading information and academic dishonesty. Previous research has primarily focused on classifying text as either entirely human-written or LLM-generated, neglecting the detection of mixed texts that contain both types of content.",a token classification problem,sciIE,LLM's textual representation counterparts,False,4,1,5,3.333333333333333
1-4330_cca3fb24-9267-4e27-941e-55040f509ca5,noy.sternlicht@mail.huji.ac.il,"There is a growing concern about distinguishing between LLM-generated and human-written texts to prevent misuse, such as the dissemination of misleading information and academic dishonesty. Previous research has primarily focused on classifying text as either entirely human-written or LLM-generated, neglecting the detection of mixed texts that contain both types of content.",a token classification problem,mpnet_zero,an LLM that effectively processes textual information,False,4,1,6,4.0
1-4330_cca3fb24-9267-4e27-941e-55040f509ca5,noy.sternlicht@mail.huji.ac.il,"There is a growing concern about distinguishing between LLM-generated and human-written texts to prevent misuse, such as the dissemination of misleading information and academic dishonesty. Previous research has primarily focused on classifying text as either entirely human-written or LLM-generated, neglecting the detection of mixed texts that contain both types of content.",a token classification problem,positive,a token classification problem,False,4,1,2,1.3333333333333333
1-2288_347a15a9-1b5a-49bf-92a8-a2b9d4cee10d,noy.sternlicht@mail.huji.ac.il,"The abstract highlights issues of inconsistent conceptualization and vague expression in existing NLG quality criteria, which reduce the reliability of LLM evaluations. Additionally, it points out the confusion inherent in LLMs regarding different evaluation criteria, indicating a need for further research and improvements in LLM-based evaluation methods.",behavioral testing,gpt-4o,human linguistic judgment,False,2,1,3,1.0
1-2288_347a15a9-1b5a-49bf-92a8-a2b9d4cee10d,noy.sternlicht@mail.huji.ac.il,"The abstract highlights issues of inconsistent conceptualization and vague expression in existing NLG quality criteria, which reduce the reliability of LLM evaluations. Additionally, it points out the confusion inherent in LLMs regarding different evaluation criteria, indicating a need for further research and improvements in LLM-based evaluation methods.",behavioral testing,ours,human evaluation,False,2,1,1,0.3333333333333333
1-2288_347a15a9-1b5a-49bf-92a8-a2b9d4cee10d,noy.sternlicht@mail.huji.ac.il,"The abstract highlights issues of inconsistent conceptualization and vague expression in existing NLG quality criteria, which reduce the reliability of LLM evaluations. Additionally, it points out the confusion inherent in LLMs regarding different evaluation criteria, indicating a need for further research and improvements in LLM-based evaluation methods.",behavioral testing,sciIE,LLM-based automatic evaluation metric,False,2,1,4,1.3333333333333333
1-2288_347a15a9-1b5a-49bf-92a8-a2b9d4cee10d,noy.sternlicht@mail.huji.ac.il,"The abstract highlights issues of inconsistent conceptualization and vague expression in existing NLG quality criteria, which reduce the reliability of LLM evaluations. Additionally, it points out the confusion inherent in LLMs regarding different evaluation criteria, indicating a need for further research and improvements in LLM-based evaluation methods.",behavioral testing,random,implicit feature embeddings,False,2,1,5,1.6666666666666665
1-2288_347a15a9-1b5a-49bf-92a8-a2b9d4cee10d,noy.sternlicht@mail.huji.ac.il,"The abstract highlights issues of inconsistent conceptualization and vague expression in existing NLG quality criteria, which reduce the reliability of LLM evaluations. Additionally, it points out the confusion inherent in LLMs regarding different evaluation criteria, indicating a need for further research and improvements in LLM-based evaluation methods.",behavioral testing,mpnet_zero,evaluating the quality of text generated by generative Large Language Models(LLMs),False,2,1,6,2.0
1-2288_347a15a9-1b5a-49bf-92a8-a2b9d4cee10d,noy.sternlicht@mail.huji.ac.il,"The abstract highlights issues of inconsistent conceptualization and vague expression in existing NLG quality criteria, which reduce the reliability of LLM evaluations. Additionally, it points out the confusion inherent in LLMs regarding different evaluation criteria, indicating a need for further research and improvements in LLM-based evaluation methods.",behavioral testing,positive,behavioral testing,False,2,1,2,0.6666666666666666
1-11323_c67c7988-f949-4d36-bbbc-8c0c132d9a4c,noy.sternlicht@mail.huji.ac.il,"Aligning language models with human preferences is crucial for better meeting diverse user needs, and there is a need to effectively transfer alignment behavior from weaker models to stronger ones. The observation that stronger models can benefit from the alignment capabilities of weaker models highlights a gap in existing approaches to model alignment.",weak-to-strong generalization,mpnet_zero,the language model alignment,False,3,1,2,1.0
1-11323_c67c7988-f949-4d36-bbbc-8c0c132d9a4c,noy.sternlicht@mail.huji.ac.il,"Aligning language models with human preferences is crucial for better meeting diverse user needs, and there is a need to effectively transfer alignment behavior from weaker models to stronger ones. The observation that stronger models can benefit from the alignment capabilities of weaker models highlights a gap in existing approaches to model alignment.",weak-to-strong generalization,gpt-4o,human collaborative learning,False,3,1,3,1.5
1-11323_c67c7988-f949-4d36-bbbc-8c0c132d9a4c,noy.sternlicht@mail.huji.ac.il,"Aligning language models with human preferences is crucial for better meeting diverse user needs, and there is a need to effectively transfer alignment behavior from weaker models to stronger ones. The observation that stronger models can benefit from the alignment capabilities of weaker models highlights a gap in existing approaches to model alignment.",weak-to-strong generalization,sciIE,language model fine-tuning techniques,False,3,1,5,2.5
1-11323_c67c7988-f949-4d36-bbbc-8c0c132d9a4c,noy.sternlicht@mail.huji.ac.il,"Aligning language models with human preferences is crucial for better meeting diverse user needs, and there is a need to effectively transfer alignment behavior from weaker models to stronger ones. The observation that stronger models can benefit from the alignment capabilities of weaker models highlights a gap in existing approaches to model alignment.",weak-to-strong generalization,positive,weak-to-strong generalization,False,3,1,4,2.0
1-11323_c67c7988-f949-4d36-bbbc-8c0c132d9a4c,noy.sternlicht@mail.huji.ac.il,"Aligning language models with human preferences is crucial for better meeting diverse user needs, and there is a need to effectively transfer alignment behavior from weaker models to stronger ones. The observation that stronger models can benefit from the alignment capabilities of weaker models highlights a gap in existing approaches to model alignment.",weak-to-strong generalization,random,partitioning large-scale hypergraphs,False,3,1,6,3.0
1-11323_c67c7988-f949-4d36-bbbc-8c0c132d9a4c,noy.sternlicht@mail.huji.ac.il,"Aligning language models with human preferences is crucial for better meeting diverse user needs, and there is a need to effectively transfer alignment behavior from weaker models to stronger ones. The observation that stronger models can benefit from the alignment capabilities of weaker models highlights a gap in existing approaches to model alignment.",weak-to-strong generalization,ours,aligning Large Language Models with human preferences,False,3,1,1,0.5
1-40766_f1a0dc30-65c4-49c6-b3a5-659c27e6fc78,noy.sternlicht@mail.huji.ac.il,"The application of large language models (LLMs) as evaluators in pairwise comparisons often leads to selection bias, resulting in inconsistent judgments that compromise the fairness and effectiveness of evaluation results. This highlights a significant challenge in developing reliable automated evaluation frameworks that can mitigate such biases and improve performance in AI-driven assessments.",an optimization task aimed at adjusting observed prediction distributions to align with unbiased prediction distributions,ours,bias examination,False,2,1,5,1.6666666666666665
1-40766_f1a0dc30-65c4-49c6-b3a5-659c27e6fc78,noy.sternlicht@mail.huji.ac.il,"The application of large language models (LLMs) as evaluators in pairwise comparisons often leads to selection bias, resulting in inconsistent judgments that compromise the fairness and effectiveness of evaluation results. This highlights a significant challenge in developing reliable automated evaluation frameworks that can mitigate such biases and improve performance in AI-driven assessments.",an optimization task aimed at adjusting observed prediction distributions to align with unbiased prediction distributions,gpt-4o,adversarial training,False,2,1,2,0.6666666666666666
1-40766_f1a0dc30-65c4-49c6-b3a5-659c27e6fc78,noy.sternlicht@mail.huji.ac.il,"The application of large language models (LLMs) as evaluators in pairwise comparisons often leads to selection bias, resulting in inconsistent judgments that compromise the fairness and effectiveness of evaluation results. This highlights a significant challenge in developing reliable automated evaluation frameworks that can mitigate such biases and improve performance in AI-driven assessments.",an optimization task aimed at adjusting observed prediction distributions to align with unbiased prediction distributions,mpnet_zero,Large Language Model Bias Index,False,2,1,4,1.3333333333333333
1-40766_f1a0dc30-65c4-49c6-b3a5-659c27e6fc78,noy.sternlicht@mail.huji.ac.il,"The application of large language models (LLMs) as evaluators in pairwise comparisons often leads to selection bias, resulting in inconsistent judgments that compromise the fairness and effectiveness of evaluation results. This highlights a significant challenge in developing reliable automated evaluation frameworks that can mitigate such biases and improve performance in AI-driven assessments.",an optimization task aimed at adjusting observed prediction distributions to align with unbiased prediction distributions,positive,an optimization task aimed at adjusting observed prediction distributions to align with unbiased prediction distributions,False,2,1,1,0.3333333333333333
1-40766_f1a0dc30-65c4-49c6-b3a5-659c27e6fc78,noy.sternlicht@mail.huji.ac.il,"The application of large language models (LLMs) as evaluators in pairwise comparisons often leads to selection bias, resulting in inconsistent judgments that compromise the fairness and effectiveness of evaluation results. This highlights a significant challenge in developing reliable automated evaluation frameworks that can mitigate such biases and improve performance in AI-driven assessments.",an optimization task aimed at adjusting observed prediction distributions to align with unbiased prediction distributions,sciIE,Large Language Model Bias Index (LLMBI),False,2,1,3,1.0
1-40766_f1a0dc30-65c4-49c6-b3a5-659c27e6fc78,noy.sternlicht@mail.huji.ac.il,"The application of large language models (LLMs) as evaluators in pairwise comparisons often leads to selection bias, resulting in inconsistent judgments that compromise the fairness and effectiveness of evaluation results. This highlights a significant challenge in developing reliable automated evaluation frameworks that can mitigate such biases and improve performance in AI-driven assessments.",an optimization task aimed at adjusting observed prediction distributions to align with unbiased prediction distributions,random,a human-written document,False,2,1,6,2.0
1-31947_b1f88262-1a96-403f-869a-81fc0a4265a7,noy.sternlicht@mail.huji.ac.il,"Large language models (LLMs) often struggle to provide up-to-date information due to their one-time training and the constantly evolving nature of the world. Existing approaches to keep LLMs current face difficulties in extracting stored knowledge, highlighting a need for improved methods of knowledge acquisition from raw documents.",the remarkable success of the Feynman Technique in efficient human learning,gpt-4o,neuroscience-inspired memory consolidation,False,3,1,4,2.0
1-31947_b1f88262-1a96-403f-869a-81fc0a4265a7,noy.sternlicht@mail.huji.ac.il,"Large language models (LLMs) often struggle to provide up-to-date information due to their one-time training and the constantly evolving nature of the world. Existing approaches to keep LLMs current face difficulties in extracting stored knowledge, highlighting a need for improved methods of knowledge acquisition from raw documents.",the remarkable success of the Feynman Technique in efficient human learning,ours,"neuroscience, where the human brain often sheds outdated information to improve the retention of crucial knowledge and facilitate the acquisition of new information",False,3,1,1,0.5
1-31947_b1f88262-1a96-403f-869a-81fc0a4265a7,noy.sternlicht@mail.huji.ac.il,"Large language models (LLMs) often struggle to provide up-to-date information due to their one-time training and the constantly evolving nature of the world. Existing approaches to keep LLMs current face difficulties in extracting stored knowledge, highlighting a need for improved methods of knowledge acquisition from raw documents.",the remarkable success of the Feynman Technique in efficient human learning,sciIE,open-source large language models (LLMs),False,3,1,5,2.5
1-31947_b1f88262-1a96-403f-869a-81fc0a4265a7,noy.sternlicht@mail.huji.ac.il,"Large language models (LLMs) often struggle to provide up-to-date information due to their one-time training and the constantly evolving nature of the world. Existing approaches to keep LLMs current face difficulties in extracting stored knowledge, highlighting a need for improved methods of knowledge acquisition from raw documents.",the remarkable success of the Feynman Technique in efficient human learning,random,large foundation models,False,3,1,6,3.0
1-31947_b1f88262-1a96-403f-869a-81fc0a4265a7,noy.sternlicht@mail.huji.ac.il,"Large language models (LLMs) often struggle to provide up-to-date information due to their one-time training and the constantly evolving nature of the world. Existing approaches to keep LLMs current face difficulties in extracting stored knowledge, highlighting a need for improved methods of knowledge acquisition from raw documents.",the remarkable success of the Feynman Technique in efficient human learning,mpnet_zero,the fusion between distribution of large language models knowledge and distribution of retrieved texts,False,3,1,3,1.5
1-31947_b1f88262-1a96-403f-869a-81fc0a4265a7,noy.sternlicht@mail.huji.ac.il,"Large language models (LLMs) often struggle to provide up-to-date information due to their one-time training and the constantly evolving nature of the world. Existing approaches to keep LLMs current face difficulties in extracting stored knowledge, highlighting a need for improved methods of knowledge acquisition from raw documents.",the remarkable success of the Feynman Technique in efficient human learning,positive,the remarkable success of the Feynman Technique in efficient human learning,False,3,1,2,1.0
1-641_e3d9632c-90a7-45f0-a4dc-e89908811948,noy.sternlicht@mail.huji.ac.il,"Model attribution for LLM-generated disinformation is challenging due to the human-like quality of the disinformation produced and the diversity in prompting methods, which complicates accurate source attribution. An effective attribution model must be invariant to domain-specific features and proficient in identifying originating models across various scenarios, reflecting real-world detection challenges.",a domain generalization problem,ours,the attribution task,False,2,1,4,1.3333333333333333
1-641_e3d9632c-90a7-45f0-a4dc-e89908811948,noy.sternlicht@mail.huji.ac.il,"Model attribution for LLM-generated disinformation is challenging due to the human-like quality of the disinformation produced and the diversity in prompting methods, which complicates accurate source attribution. An effective attribution model must be invariant to domain-specific features and proficient in identifying originating models across various scenarios, reflecting real-world detection challenges.",a domain generalization problem,mpnet_zero,independent disinformation generation characteristics of various large language models,False,2,1,3,1.0
1-641_e3d9632c-90a7-45f0-a4dc-e89908811948,noy.sternlicht@mail.huji.ac.il,"Model attribution for LLM-generated disinformation is challenging due to the human-like quality of the disinformation produced and the diversity in prompting methods, which complicates accurate source attribution. An effective attribution model must be invariant to domain-specific features and proficient in identifying originating models across various scenarios, reflecting real-world detection challenges.",a domain generalization problem,sciIE,Detecting Misinformation by Integrating Intent featuRes (DM-INTER),False,2,1,1,0.3333333333333333
1-641_e3d9632c-90a7-45f0-a4dc-e89908811948,noy.sternlicht@mail.huji.ac.il,"Model attribution for LLM-generated disinformation is challenging due to the human-like quality of the disinformation produced and the diversity in prompting methods, which complicates accurate source attribution. An effective attribution model must be invariant to domain-specific features and proficient in identifying originating models across various scenarios, reflecting real-world detection challenges.",a domain generalization problem,positive,a domain generalization problem,False,2,1,5,1.6666666666666665
1-641_e3d9632c-90a7-45f0-a4dc-e89908811948,noy.sternlicht@mail.huji.ac.il,"Model attribution for LLM-generated disinformation is challenging due to the human-like quality of the disinformation produced and the diversity in prompting methods, which complicates accurate source attribution. An effective attribution model must be invariant to domain-specific features and proficient in identifying originating models across various scenarios, reflecting real-world detection challenges.",a domain generalization problem,random,a self-evolving framework,False,2,1,6,2.0
1-641_e3d9632c-90a7-45f0-a4dc-e89908811948,noy.sternlicht@mail.huji.ac.il,"Model attribution for LLM-generated disinformation is challenging due to the human-like quality of the disinformation produced and the diversity in prompting methods, which complicates accurate source attribution. An effective attribution model must be invariant to domain-specific features and proficient in identifying originating models across various scenarios, reflecting real-world detection challenges.",a domain generalization problem,gpt-4o,forensic linguistics,False,2,1,2,0.6666666666666666
1-30045_e2830c52-6a9e-484e-afb0-191398e9b81b,noy.sternlicht@mail.huji.ac.il,"The reasoning ability of large language models (LLMs) is limited in mathematical reasoning, which is crucial for various fields such as healthcare, transport, and aerospace. There is a significant need to enhance the mathematical reasoning capabilities of LLMs to address this gap and improve their performance in solving mathematical problems.",the human learning process of generalization of learned information and effective application of previous knowledge in new reasoning tasks,gpt-4o,symbolic reasoning techniques,False,3,1,2,1.0
1-30045_e2830c52-6a9e-484e-afb0-191398e9b81b,noy.sternlicht@mail.huji.ac.il,"The reasoning ability of large language models (LLMs) is limited in mathematical reasoning, which is crucial for various fields such as healthcare, transport, and aerospace. There is a significant need to enhance the mathematical reasoning capabilities of LLMs to address this gap and improve their performance in solving mathematical problems.",the human learning process of generalization of learned information and effective application of previous knowledge in new reasoning tasks,sciIE,Large-Language model (LLM),False,3,1,5,2.5
1-30045_e2830c52-6a9e-484e-afb0-191398e9b81b,noy.sternlicht@mail.huji.ac.il,"The reasoning ability of large language models (LLMs) is limited in mathematical reasoning, which is crucial for various fields such as healthcare, transport, and aerospace. There is a significant need to enhance the mathematical reasoning capabilities of LLMs to address this gap and improve their performance in solving mathematical problems.",the human learning process of generalization of learned information and effective application of previous knowledge in new reasoning tasks,random,self-distillation,False,3,1,6,3.0
1-30045_e2830c52-6a9e-484e-afb0-191398e9b81b,noy.sternlicht@mail.huji.ac.il,"The reasoning ability of large language models (LLMs) is limited in mathematical reasoning, which is crucial for various fields such as healthcare, transport, and aerospace. There is a significant need to enhance the mathematical reasoning capabilities of LLMs to address this gap and improve their performance in solving mathematical problems.",the human learning process of generalization of learned information and effective application of previous knowledge in new reasoning tasks,ours,the cognitive mechanism in human mathematical learning,False,3,1,3,1.5
1-30045_e2830c52-6a9e-484e-afb0-191398e9b81b,noy.sternlicht@mail.huji.ac.il,"The reasoning ability of large language models (LLMs) is limited in mathematical reasoning, which is crucial for various fields such as healthcare, transport, and aerospace. There is a significant need to enhance the mathematical reasoning capabilities of LLMs to address this gap and improve their performance in solving mathematical problems.",the human learning process of generalization of learned information and effective application of previous knowledge in new reasoning tasks,mpnet_zero,improve the reasoning capabilities of Large Language Models,False,3,1,4,2.0
1-30045_e2830c52-6a9e-484e-afb0-191398e9b81b,noy.sternlicht@mail.huji.ac.il,"The reasoning ability of large language models (LLMs) is limited in mathematical reasoning, which is crucial for various fields such as healthcare, transport, and aerospace. There is a significant need to enhance the mathematical reasoning capabilities of LLMs to address this gap and improve their performance in solving mathematical problems.",the human learning process of generalization of learned information and effective application of previous knowledge in new reasoning tasks,positive,the human learning process of generalization of learned information and effective application of previous knowledge in new reasoning tasks,False,3,1,1,0.5
1-31809_e5ffa1fb-0958-4eeb-a7e1-a0efae1ae46f,noy.sternlicht@mail.huji.ac.il,"The task of finding plausible knowledge missing from a given ontology is highly challenging, particularly for Large Language Models, even after fine-tuning. Additionally, there is a need to evaluate and compare different approaches to ontology completion, as previous research has not thoroughly analyzed their effectiveness or the potential for hybrid strategies.",a generalisation of the well-studied taxonomy expansion task,gpt-4o,knowledge graph embeddings,False,3,1,2,1.0
1-31809_e5ffa1fb-0958-4eeb-a7e1-a0efae1ae46f,noy.sternlicht@mail.huji.ac.il,"The task of finding plausible knowledge missing from a given ontology is highly challenging, particularly for Large Language Models, even after fine-tuning. Additionally, there is a need to evaluate and compare different approaches to ontology completion, as previous research has not thoroughly analyzed their effectiveness or the potential for hybrid strategies.",a generalisation of the well-studied taxonomy expansion task,ours,a knowledge graph completion problem,False,3,1,1,0.5
1-31809_e5ffa1fb-0958-4eeb-a7e1-a0efae1ae46f,noy.sternlicht@mail.huji.ac.il,"The task of finding plausible knowledge missing from a given ontology is highly challenging, particularly for Large Language Models, even after fine-tuning. Additionally, there is a need to evaluate and compare different approaches to ontology completion, as previous research has not thoroughly analyzed their effectiveness or the potential for hybrid strategies.",a generalisation of the well-studied taxonomy expansion task,random,nodes in a bipartite graph that is fully connected,False,3,1,6,3.0
1-31809_e5ffa1fb-0958-4eeb-a7e1-a0efae1ae46f,noy.sternlicht@mail.huji.ac.il,"The task of finding plausible knowledge missing from a given ontology is highly challenging, particularly for Large Language Models, even after fine-tuning. Additionally, there is a need to evaluate and compare different approaches to ontology completion, as previous research has not thoroughly analyzed their effectiveness or the potential for hybrid strategies.",a generalisation of the well-studied taxonomy expansion task,positive,a generalisation of the well-studied taxonomy expansion task,False,3,1,3,1.5
1-31809_e5ffa1fb-0958-4eeb-a7e1-a0efae1ae46f,noy.sternlicht@mail.huji.ac.il,"The task of finding plausible knowledge missing from a given ontology is highly challenging, particularly for Large Language Models, even after fine-tuning. Additionally, there is a need to evaluate and compare different approaches to ontology completion, as previous research has not thoroughly analyzed their effectiveness or the potential for hybrid strategies.",a generalisation of the well-studied taxonomy expansion task,mpnet_zero,ontological knowledge,False,3,1,5,2.5
1-31809_e5ffa1fb-0958-4eeb-a7e1-a0efae1ae46f,noy.sternlicht@mail.huji.ac.il,"The task of finding plausible knowledge missing from a given ontology is highly challenging, particularly for Large Language Models, even after fine-tuning. Additionally, there is a need to evaluate and compare different approaches to ontology completion, as previous research has not thoroughly analyzed their effectiveness or the potential for hybrid strategies.",a generalisation of the well-studied taxonomy expansion task,sciIE,Ontology Learning,False,3,1,4,2.0
1-37477_965f8f3c-3de0-4230-ae87-1c1c5483ca32,noy.sternlicht@mail.huji.ac.il,"The study addresses the challenge of factual inaccuracies in the output of large language models, which can undermine the reliability of their responses. It highlights the need for effective methods to improve the retrieval of relevant factual information to enhance the accuracy of these models' answers.",the cognitive linguistic theory of frame semantics,ours,the bag-of-words assumption in information retrieval,False,3,1,4,2.0
1-37477_965f8f3c-3de0-4230-ae87-1c1c5483ca32,noy.sternlicht@mail.huji.ac.il,"The study addresses the challenge of factual inaccuracies in the output of large language models, which can undermine the reliability of their responses. It highlights the need for effective methods to improve the retrieval of relevant factual information to enhance the accuracy of these models' answers.",the cognitive linguistic theory of frame semantics,mpnet_zero,general fact-checking capabilities of pre-trained language models,False,3,1,3,1.5
1-37477_965f8f3c-3de0-4230-ae87-1c1c5483ca32,noy.sternlicht@mail.huji.ac.il,"The study addresses the challenge of factual inaccuracies in the output of large language models, which can undermine the reliability of their responses. It highlights the need for effective methods to improve the retrieval of relevant factual information to enhance the accuracy of these models' answers.",the cognitive linguistic theory of frame semantics,random,Visual in-context learning,False,3,1,6,3.0
1-37477_965f8f3c-3de0-4230-ae87-1c1c5483ca32,noy.sternlicht@mail.huji.ac.il,"The study addresses the challenge of factual inaccuracies in the output of large language models, which can undermine the reliability of their responses. It highlights the need for effective methods to improve the retrieval of relevant factual information to enhance the accuracy of these models' answers.",the cognitive linguistic theory of frame semantics,gpt-4o,search engine algorithms,False,3,1,2,1.0
1-37477_965f8f3c-3de0-4230-ae87-1c1c5483ca32,noy.sternlicht@mail.huji.ac.il,"The study addresses the challenge of factual inaccuracies in the output of large language models, which can undermine the reliability of their responses. It highlights the need for effective methods to improve the retrieval of relevant factual information to enhance the accuracy of these models' answers.",the cognitive linguistic theory of frame semantics,positive,the cognitive linguistic theory of frame semantics,False,3,1,1,0.5
1-37477_965f8f3c-3de0-4230-ae87-1c1c5483ca32,noy.sternlicht@mail.huji.ac.il,"The study addresses the challenge of factual inaccuracies in the output of large language models, which can undermine the reliability of their responses. It highlights the need for effective methods to improve the retrieval of relevant factual information to enhance the accuracy of these models' answers.",the cognitive linguistic theory of frame semantics,sciIE,large-scale language models (LLMs),False,3,1,5,2.5
1-710_6debd94c-e2b4-4874-a585-24876952adbb,noy.sternlicht@mail.huji.ac.il,"The propagation of social biases within large language models, inherited from diverse training datasets, presents a significant challenge in understanding and mitigating these biases. There is a necessity for tailored debiasing strategies and a deeper understanding of the complex mechanisms and pathways through which bias operates in these models.",causal mediation analysis,random,a Lagrangian-mechanics-based physical model,False,2,1,6,2.0
1-710_6debd94c-e2b4-4874-a585-24876952adbb,noy.sternlicht@mail.huji.ac.il,"The propagation of social biases within large language models, inherited from diverse training datasets, presents a significant challenge in understanding and mitigating these biases. There is a necessity for tailored debiasing strategies and a deeper understanding of the complex mechanisms and pathways through which bias operates in these models.",causal mediation analysis,gpt-4o,cultural evolution theory,False,2,1,2,0.6666666666666666
1-710_6debd94c-e2b4-4874-a585-24876952adbb,noy.sternlicht@mail.huji.ac.il,"The propagation of social biases within large language models, inherited from diverse training datasets, presents a significant challenge in understanding and mitigating these biases. There is a necessity for tailored debiasing strategies and a deeper understanding of the complex mechanisms and pathways through which bias operates in these models.",causal mediation analysis,mpnet_zero,studying biases and inherent knowledge of large language modelss,False,2,1,3,1.0
1-710_6debd94c-e2b4-4874-a585-24876952adbb,noy.sternlicht@mail.huji.ac.il,"The propagation of social biases within large language models, inherited from diverse training datasets, presents a significant challenge in understanding and mitigating these biases. There is a necessity for tailored debiasing strategies and a deeper understanding of the complex mechanisms and pathways through which bias operates in these models.",causal mediation analysis,sciIE,Large Language Model Bias Index (LLMBI),False,2,1,4,1.3333333333333333
1-710_6debd94c-e2b4-4874-a585-24876952adbb,noy.sternlicht@mail.huji.ac.il,"The propagation of social biases within large language models, inherited from diverse training datasets, presents a significant challenge in understanding and mitigating these biases. There is a necessity for tailored debiasing strategies and a deeper understanding of the complex mechanisms and pathways through which bias operates in these models.",causal mediation analysis,positive,causal mediation analysis,False,2,1,5,1.6666666666666665
1-710_6debd94c-e2b4-4874-a585-24876952adbb,noy.sternlicht@mail.huji.ac.il,"The propagation of social biases within large language models, inherited from diverse training datasets, presents a significant challenge in understanding and mitigating these biases. There is a necessity for tailored debiasing strategies and a deeper understanding of the complex mechanisms and pathways through which bias operates in these models.",causal mediation analysis,ours,the spread of rumors or influence in an online social network,False,2,1,1,0.3333333333333333
1-34117_868de9d7-8184-4bfc-b655-a3df1c2c4980,noy.sternlicht@mail.huji.ac.il,"Assessing long-form responses generated by Vision-Language Models (VLMs) is challenging due to the need to verify both adherence to instructions and the grounding of text outputs in the provided images. This highlights a gap in effective evaluation methods for VLMs, necessitating innovative approaches to improve assessment accuracy and transparency.",evaluating LMs with LMs,gpt-4o,human visual perception,False,2,1,4,1.3333333333333333
1-34117_868de9d7-8184-4bfc-b655-a3df1c2c4980,noy.sternlicht@mail.huji.ac.il,"Assessing long-form responses generated by Vision-Language Models (VLMs) is challenging due to the need to verify both adherence to instructions and the grounding of text outputs in the provided images. This highlights a gap in effective evaluation methods for VLMs, necessitating innovative approaches to improve assessment accuracy and transparency.",evaluating LMs with LMs,positive,evaluating LMs with LMs,False,2,1,2,0.6666666666666666
1-34117_868de9d7-8184-4bfc-b655-a3df1c2c4980,noy.sternlicht@mail.huji.ac.il,"Assessing long-form responses generated by Vision-Language Models (VLMs) is challenging due to the need to verify both adherence to instructions and the grounding of text outputs in the provided images. This highlights a gap in effective evaluation methods for VLMs, necessitating innovative approaches to improve assessment accuracy and transparency.",evaluating LMs with LMs,random,the parameters trained with gradient descent,False,2,1,6,2.0
1-34117_868de9d7-8184-4bfc-b655-a3df1c2c4980,noy.sternlicht@mail.huji.ac.il,"Assessing long-form responses generated by Vision-Language Models (VLMs) is challenging due to the need to verify both adherence to instructions and the grounding of text outputs in the provided images. This highlights a gap in effective evaluation methods for VLMs, necessitating innovative approaches to improve assessment accuracy and transparency.",evaluating LMs with LMs,ours,human evaluation,False,2,1,3,1.0
1-34117_868de9d7-8184-4bfc-b655-a3df1c2c4980,noy.sternlicht@mail.huji.ac.il,"Assessing long-form responses generated by Vision-Language Models (VLMs) is challenging due to the need to verify both adherence to instructions and the grounding of text outputs in the provided images. This highlights a gap in effective evaluation methods for VLMs, necessitating innovative approaches to improve assessment accuracy and transparency.",evaluating LMs with LMs,sciIE,multimodal vision-language models (VLMs),False,2,1,5,1.6666666666666665
1-34117_868de9d7-8184-4bfc-b655-a3df1c2c4980,noy.sternlicht@mail.huji.ac.il,"Assessing long-form responses generated by Vision-Language Models (VLMs) is challenging due to the need to verify both adherence to instructions and the grounding of text outputs in the provided images. This highlights a gap in effective evaluation methods for VLMs, necessitating innovative approaches to improve assessment accuracy and transparency.",evaluating LMs with LMs,mpnet_zero,evaluate high-level cognitive ability of Large Vision-Language Models using images with rich semantics,False,2,1,1,0.3333333333333333
1-28499_a7ef1baf-ab5c-453f-915e-f7d3429a8017,noy.sternlicht@mail.huji.ac.il,"To enhance zero-shot translation, models need to share knowledge across languages, which is a challenge in many-to-many multilingual neural machine translation. Existing methods may not effectively leverage both semantic and linguistic features, limiting their ability to improve translation performance across diverse languages.",the process of integrating semantic features from the source sentences and linguistic features from the target sentences,ours,quantifying the alignment and overlap of concepts across languages in multilingual embeddings,False,3,1,1,0.5
1-28499_a7ef1baf-ab5c-453f-915e-f7d3429a8017,noy.sternlicht@mail.huji.ac.il,"To enhance zero-shot translation, models need to share knowledge across languages, which is a challenge in many-to-many multilingual neural machine translation. Existing methods may not effectively leverage both semantic and linguistic features, limiting their ability to improve translation performance across diverse languages.",the process of integrating semantic features from the source sentences and linguistic features from the target sentences,mpnet_zero,Multilingual neural machine translation models,False,3,1,3,1.5
1-28499_a7ef1baf-ab5c-453f-915e-f7d3429a8017,noy.sternlicht@mail.huji.ac.il,"To enhance zero-shot translation, models need to share knowledge across languages, which is a challenge in many-to-many multilingual neural machine translation. Existing methods may not effectively leverage both semantic and linguistic features, limiting their ability to improve translation performance across diverse languages.",the process of integrating semantic features from the source sentences and linguistic features from the target sentences,positive,the process of integrating semantic features from the source sentences and linguistic features from the target sentences,False,3,1,2,1.0
1-28499_a7ef1baf-ab5c-453f-915e-f7d3429a8017,noy.sternlicht@mail.huji.ac.il,"To enhance zero-shot translation, models need to share knowledge across languages, which is a challenge in many-to-many multilingual neural machine translation. Existing methods may not effectively leverage both semantic and linguistic features, limiting their ability to improve translation performance across diverse languages.",the process of integrating semantic features from the source sentences and linguistic features from the target sentences,sciIE,Pre-trained sequence-to-sequence (seq2seq) multi-lingual models,False,3,1,4,2.0
1-28499_a7ef1baf-ab5c-453f-915e-f7d3429a8017,noy.sternlicht@mail.huji.ac.il,"To enhance zero-shot translation, models need to share knowledge across languages, which is a challenge in many-to-many multilingual neural machine translation. Existing methods may not effectively leverage both semantic and linguistic features, limiting their ability to improve translation performance across diverse languages.",the process of integrating semantic features from the source sentences and linguistic features from the target sentences,random,cognitive load theory,False,3,1,6,3.0
1-28499_a7ef1baf-ab5c-453f-915e-f7d3429a8017,noy.sternlicht@mail.huji.ac.il,"To enhance zero-shot translation, models need to share knowledge across languages, which is a challenge in many-to-many multilingual neural machine translation. Existing methods may not effectively leverage both semantic and linguistic features, limiting their ability to improve translation performance across diverse languages.",the process of integrating semantic features from the source sentences and linguistic features from the target sentences,gpt-4o,multilingual pretraining,False,3,1,5,2.5
1-7666_2a8784a6-8ba4-427a-83c8-f512ec6d752c,noy.sternlicht@mail.huji.ac.il,"Existing methods for early exiting in large language models require significant effort to train internal classifiers and can only achieve comparable performance at best, highlighting a need for more efficient approaches. Additionally, the high computational overhead associated with model inference presents a challenge that necessitates innovative solutions to accelerate inference while maintaining performance.",a distribution prediction problem,ours,a sequential decision-making problem,False,2,1,2,0.6666666666666666
1-7666_2a8784a6-8ba4-427a-83c8-f512ec6d752c,noy.sternlicht@mail.huji.ac.il,"Existing methods for early exiting in large language models require significant effort to train internal classifiers and can only achieve comparable performance at best, highlighting a need for more efficient approaches. Additionally, the high computational overhead associated with model inference presents a challenge that necessitates innovative solutions to accelerate inference while maintaining performance.",a distribution prediction problem,gpt-4o,dynamic neural networks,False,2,1,3,1.0
1-7666_2a8784a6-8ba4-427a-83c8-f512ec6d752c,noy.sternlicht@mail.huji.ac.il,"Existing methods for early exiting in large language models require significant effort to train internal classifiers and can only achieve comparable performance at best, highlighting a need for more efficient approaches. Additionally, the high computational overhead associated with model inference presents a challenge that necessitates innovative solutions to accelerate inference while maintaining performance.",a distribution prediction problem,sciIE,few-shot capabilities of large language models,False,2,1,1,0.3333333333333333
1-7666_2a8784a6-8ba4-427a-83c8-f512ec6d752c,noy.sternlicht@mail.huji.ac.il,"Existing methods for early exiting in large language models require significant effort to train internal classifiers and can only achieve comparable performance at best, highlighting a need for more efficient approaches. Additionally, the high computational overhead associated with model inference presents a challenge that necessitates innovative solutions to accelerate inference while maintaining performance.",a distribution prediction problem,random,Vision-Language foundation models (VL-models),False,2,1,5,1.6666666666666665
1-7666_2a8784a6-8ba4-427a-83c8-f512ec6d752c,noy.sternlicht@mail.huji.ac.il,"Existing methods for early exiting in large language models require significant effort to train internal classifiers and can only achieve comparable performance at best, highlighting a need for more efficient approaches. Additionally, the high computational overhead associated with model inference presents a challenge that necessitates innovative solutions to accelerate inference while maintaining performance.",a distribution prediction problem,mpnet_zero,recent success of Large Language Models,False,2,1,6,2.0
1-7666_2a8784a6-8ba4-427a-83c8-f512ec6d752c,noy.sternlicht@mail.huji.ac.il,"Existing methods for early exiting in large language models require significant effort to train internal classifiers and can only achieve comparable performance at best, highlighting a need for more efficient approaches. Additionally, the high computational overhead associated with model inference presents a challenge that necessitates innovative solutions to accelerate inference while maintaining performance.",a distribution prediction problem,positive,a distribution prediction problem,False,2,1,4,1.3333333333333333
1-41666_89a913b3-9f44-4ee4-80d9-4861ab8d754d,noy.sternlicht@mail.huji.ac.il,"The study addresses the challenge of effectively generating AI research leaderboards by extracting specific quadruples from scholarly articles, highlighting the limitations of traditional approaches that rely on predefined taxonomies. It emphasizes the need for improved context selection to enhance the accuracy of large language models and reduce the occurrence of hallucinations in information extraction tasks.",a text generation objective,positive,a text generation objective,False,4,1,2,1.3333333333333333
1-41666_89a913b3-9f44-4ee4-80d9-4861ab8d754d,noy.sternlicht@mail.huji.ac.il,"The study addresses the challenge of effectively generating AI research leaderboards by extracting specific quadruples from scholarly articles, highlighting the limitations of traditional approaches that rely on predefined taxonomies. It emphasizes the need for improved context selection to enhance the accuracy of large language models and reduce the occurrence of hallucinations in information extraction tasks.",a text generation objective,sciIE,information extraction tasks,False,4,1,4,2.6666666666666665
1-41666_89a913b3-9f44-4ee4-80d9-4861ab8d754d,noy.sternlicht@mail.huji.ac.il,"The study addresses the challenge of effectively generating AI research leaderboards by extracting specific quadruples from scholarly articles, highlighting the limitations of traditional approaches that rely on predefined taxonomies. It emphasizes the need for improved context selection to enhance the accuracy of large language models and reduce the occurrence of hallucinations in information extraction tasks.",a text generation objective,random,parallel distributed compensation,False,4,1,6,4.0
1-41666_89a913b3-9f44-4ee4-80d9-4861ab8d754d,noy.sternlicht@mail.huji.ac.il,"The study addresses the challenge of effectively generating AI research leaderboards by extracting specific quadruples from scholarly articles, highlighting the limitations of traditional approaches that rely on predefined taxonomies. It emphasizes the need for improved context selection to enhance the accuracy of large language models and reduce the occurrence of hallucinations in information extraction tasks.",a text generation objective,gpt-4o,knowledge graph construction techniques,False,4,1,1,0.6666666666666666
1-41666_89a913b3-9f44-4ee4-80d9-4861ab8d754d,noy.sternlicht@mail.huji.ac.il,"The study addresses the challenge of effectively generating AI research leaderboards by extracting specific quadruples from scholarly articles, highlighting the limitations of traditional approaches that rely on predefined taxonomies. It emphasizes the need for improved context selection to enhance the accuracy of large language models and reduce the occurrence of hallucinations in information extraction tasks.",a text generation objective,ours,a standard question-answering task,False,4,1,3,2.0
1-41666_89a913b3-9f44-4ee4-80d9-4861ab8d754d,noy.sternlicht@mail.huji.ac.il,"The study addresses the challenge of effectively generating AI research leaderboards by extracting specific quadruples from scholarly articles, highlighting the limitations of traditional approaches that rely on predefined taxonomies. It emphasizes the need for improved context selection to enhance the accuracy of large language models and reduce the occurrence of hallucinations in information extraction tasks.",a text generation objective,mpnet_zero,for the Automatic Term Extraction and Classification (ATE) and Classification) tasks,False,4,1,5,3.333333333333333
1-447_47f54a5c-2d5a-405b-817f-76d89fc256ae,noy.sternlicht@mail.huji.ac.il,"Existing RAG models often treat LLMs as passive recipients of information, which can lead to interference from noisy retrieved content. This approach can result in conflicts between external knowledge and parametric memory, highlighting the need for improved engagement and learning from retrieved evidence.",human learning behavior,ours,"Anderson's ACT-R (Adaptive Control of Thought-Rational), a cognitive architecture modeling human information access and memory dynamics",False,3,1,1,0.5
1-447_47f54a5c-2d5a-405b-817f-76d89fc256ae,noy.sternlicht@mail.huji.ac.il,"Existing RAG models often treat LLMs as passive recipients of information, which can lead to interference from noisy retrieved content. This approach can result in conflicts between external knowledge and parametric memory, highlighting the need for improved engagement and learning from retrieved evidence.",human learning behavior,random,a biomedical-specialized pre-trained language model,False,3,1,2,1.0
1-447_47f54a5c-2d5a-405b-817f-76d89fc256ae,noy.sternlicht@mail.huji.ac.il,"Existing RAG models often treat LLMs as passive recipients of information, which can lead to interference from noisy retrieved content. This approach can result in conflicts between external knowledge and parametric memory, highlighting the need for improved engagement and learning from retrieved evidence.",human learning behavior,positive,human learning behavior,False,3,1,3,1.5
1-447_47f54a5c-2d5a-405b-817f-76d89fc256ae,noy.sternlicht@mail.huji.ac.il,"Existing RAG models often treat LLMs as passive recipients of information, which can lead to interference from noisy retrieved content. This approach can result in conflicts between external knowledge and parametric memory, highlighting the need for improved engagement and learning from retrieved evidence.",human learning behavior,sciIE,Large-Language model (LLM),False,3,1,6,3.0
1-447_47f54a5c-2d5a-405b-817f-76d89fc256ae,noy.sternlicht@mail.huji.ac.il,"Existing RAG models often treat LLMs as passive recipients of information, which can lead to interference from noisy retrieved content. This approach can result in conflicts between external knowledge and parametric memory, highlighting the need for improved engagement and learning from retrieved evidence.",human learning behavior,gpt-4o,interactive learning systems,False,3,1,5,2.5
1-447_47f54a5c-2d5a-405b-817f-76d89fc256ae,noy.sternlicht@mail.huji.ac.il,"Existing RAG models often treat LLMs as passive recipients of information, which can lead to interference from noisy retrieved content. This approach can result in conflicts between external knowledge and parametric memory, highlighting the need for improved engagement and learning from retrieved evidence.",human learning behavior,mpnet_zero,Large Language Models' knowledge recall mechanisms,False,3,1,4,2.0
1-31870_974857e0-abd8-4ef1-8ef5-2ef3a634c21f,noy.sternlicht@mail.huji.ac.il,"The internal mechanisms of how multimodal large language models process features from diverse domains remain unexplored, indicating a need for further investigation into the distribution of domain-specific neurons. Additionally, while current models demonstrate Visual Question Answering capability, they do not fully utilize domain-specific information, highlighting a gap in their effectiveness.",multilingual research,positive,multilingual research,False,2,1,2,0.6666666666666666
1-31870_974857e0-abd8-4ef1-8ef5-2ef3a634c21f,noy.sternlicht@mail.huji.ac.il,"The internal mechanisms of how multimodal large language models process features from diverse domains remain unexplored, indicating a need for further investigation into the distribution of domain-specific neurons. Additionally, while current models demonstrate Visual Question Answering capability, they do not fully utilize domain-specific information, highlighting a gap in their effectiveness.",multilingual research,sciIE,multimodal large language model,False,2,1,5,1.6666666666666665
1-31870_974857e0-abd8-4ef1-8ef5-2ef3a634c21f,noy.sternlicht@mail.huji.ac.il,"The internal mechanisms of how multimodal large language models process features from diverse domains remain unexplored, indicating a need for further investigation into the distribution of domain-specific neurons. Additionally, while current models demonstrate Visual Question Answering capability, they do not fully utilize domain-specific information, highlighting a gap in their effectiveness.",multilingual research,random,image-based generative AI,False,2,1,3,1.0
1-31870_974857e0-abd8-4ef1-8ef5-2ef3a634c21f,noy.sternlicht@mail.huji.ac.il,"The internal mechanisms of how multimodal large language models process features from diverse domains remain unexplored, indicating a need for further investigation into the distribution of domain-specific neurons. Additionally, while current models demonstrate Visual Question Answering capability, they do not fully utilize domain-specific information, highlighting a gap in their effectiveness.",multilingual research,gpt-4o,multimodal transformers,False,2,1,6,2.0
1-31870_974857e0-abd8-4ef1-8ef5-2ef3a634c21f,noy.sternlicht@mail.huji.ac.il,"The internal mechanisms of how multimodal large language models process features from diverse domains remain unexplored, indicating a need for further investigation into the distribution of domain-specific neurons. Additionally, while current models demonstrate Visual Question Answering capability, they do not fully utilize domain-specific information, highlighting a gap in their effectiveness.",multilingual research,mpnet_zero,state-of-the-art multimodal large language models,False,2,1,4,1.3333333333333333
1-31870_974857e0-abd8-4ef1-8ef5-2ef3a634c21f,noy.sternlicht@mail.huji.ac.il,"The internal mechanisms of how multimodal large language models process features from diverse domains remain unexplored, indicating a need for further investigation into the distribution of domain-specific neurons. Additionally, while current models demonstrate Visual Question Answering capability, they do not fully utilize domain-specific information, highlighting a gap in their effectiveness.",multilingual research,ours,the image-to-text mapping process by the multimodal connector,False,2,1,1,0.3333333333333333
1-40473_92341f82-89ed-4e50-a21c-e848cddb91c1,noy.sternlicht@mail.huji.ac.il,Reasoning about compositional rules is challenging because it requires multiple reasoning steps and attending to the logical relationships between elements. There is a need for effective methods to elicit rule-based reasoning in complex logical expressions.,"the Issue, Rule, Application, Conclusion (Issue, Rule, Application, Conclusion) framework, a sequential reasoning approach used by lawyers",sciIE,rule-based reasoners,False,2,1,5,1.6666666666666665
1-40473_92341f82-89ed-4e50-a21c-e848cddb91c1,noy.sternlicht@mail.huji.ac.il,Reasoning about compositional rules is challenging because it requires multiple reasoning steps and attending to the logical relationships between elements. There is a need for effective methods to elicit rule-based reasoning in complex logical expressions.,"the Issue, Rule, Application, Conclusion (Issue, Rule, Application, Conclusion) framework, a sequential reasoning approach used by lawyers",random,unitary weights,False,2,1,6,2.0
1-40473_92341f82-89ed-4e50-a21c-e848cddb91c1,noy.sternlicht@mail.huji.ac.il,Reasoning about compositional rules is challenging because it requires multiple reasoning steps and attending to the logical relationships between elements. There is a need for effective methods to elicit rule-based reasoning in complex logical expressions.,"the Issue, Rule, Application, Conclusion (Issue, Rule, Application, Conclusion) framework, a sequential reasoning approach used by lawyers",gpt-4o,symbolic logic systems,False,2,1,3,1.0
1-40473_92341f82-89ed-4e50-a21c-e848cddb91c1,noy.sternlicht@mail.huji.ac.il,Reasoning about compositional rules is challenging because it requires multiple reasoning steps and attending to the logical relationships between elements. There is a need for effective methods to elicit rule-based reasoning in complex logical expressions.,"the Issue, Rule, Application, Conclusion (Issue, Rule, Application, Conclusion) framework, a sequential reasoning approach used by lawyers",mpnet_zero,rule-based logic,False,2,1,4,1.3333333333333333
1-40473_92341f82-89ed-4e50-a21c-e848cddb91c1,noy.sternlicht@mail.huji.ac.il,Reasoning about compositional rules is challenging because it requires multiple reasoning steps and attending to the logical relationships between elements. There is a need for effective methods to elicit rule-based reasoning in complex logical expressions.,"the Issue, Rule, Application, Conclusion (Issue, Rule, Application, Conclusion) framework, a sequential reasoning approach used by lawyers",positive,"the Issue, Rule, Application, Conclusion (Issue, Rule, Application, Conclusion) framework, a sequential reasoning approach used by lawyers",False,2,1,1,0.3333333333333333
1-40473_92341f82-89ed-4e50-a21c-e848cddb91c1,noy.sternlicht@mail.huji.ac.il,Reasoning about compositional rules is challenging because it requires multiple reasoning steps and attending to the logical relationships between elements. There is a need for effective methods to elicit rule-based reasoning in complex logical expressions.,"the Issue, Rule, Application, Conclusion (Issue, Rule, Application, Conclusion) framework, a sequential reasoning approach used by lawyers",ours,Pearl's structural causal models,False,2,1,2,0.6666666666666666
1-5953_75b9e640-b5b5-4843-b993-87357fa3b599,noy.sternlicht@mail.huji.ac.il,Existing large language models (LLMs) underperform in legal judgment prediction due to challenges in understanding case complexities and distinguishing between similar charges. This highlights a need for improved methodologies that can effectively address these issues to enhance judicial efficiency.,human judicial reasoning,sciIE,large-scale legal knowledge base,False,4,1,5,3.333333333333333
1-5953_75b9e640-b5b5-4843-b993-87357fa3b599,noy.sternlicht@mail.huji.ac.il,Existing large language models (LLMs) underperform in legal judgment prediction due to challenges in understanding case complexities and distinguishing between similar charges. This highlights a need for improved methodologies that can effectively address these issues to enhance judicial efficiency.,human judicial reasoning,mpnet_zero,a multitask benchmark dataset for assessing the Arabic legal knowledge of Large Language Models,False,4,1,4,2.6666666666666665
1-5953_75b9e640-b5b5-4843-b993-87357fa3b599,noy.sternlicht@mail.huji.ac.il,Existing large language models (LLMs) underperform in legal judgment prediction due to challenges in understanding case complexities and distinguishing between similar charges. This highlights a need for improved methodologies that can effectively address these issues to enhance judicial efficiency.,human judicial reasoning,gpt-4o,case-based reasoning,False,4,1,2,1.3333333333333333
1-5953_75b9e640-b5b5-4843-b993-87357fa3b599,noy.sternlicht@mail.huji.ac.il,Existing large language models (LLMs) underperform in legal judgment prediction due to challenges in understanding case complexities and distinguishing between similar charges. This highlights a need for improved methodologies that can effectively address these issues to enhance judicial efficiency.,human judicial reasoning,random,Keyphrase Recommendation,False,4,1,6,4.0
1-5953_75b9e640-b5b5-4843-b993-87357fa3b599,noy.sternlicht@mail.huji.ac.il,Existing large language models (LLMs) underperform in legal judgment prediction due to challenges in understanding case complexities and distinguishing between similar charges. This highlights a need for improved methodologies that can effectively address these issues to enhance judicial efficiency.,human judicial reasoning,positive,human judicial reasoning,False,4,1,3,2.0
1-5953_75b9e640-b5b5-4843-b993-87357fa3b599,noy.sternlicht@mail.huji.ac.il,Existing large language models (LLMs) underperform in legal judgment prediction due to challenges in understanding case complexities and distinguishing between similar charges. This highlights a need for improved methodologies that can effectively address these issues to enhance judicial efficiency.,human judicial reasoning,ours,"the Issue, Rule, Application, Conclusion (Issue, Rule, Application, Conclusion) framework, a sequential reasoning approach used by lawyers",False,4,1,1,0.6666666666666666
1-22875_9e64c8a0-a8f1-438a-b177-a11aa8e6a2a3,noy.sternlicht@mail.huji.ac.il,"Existing methods for Emotion-Cause Pair Extraction tend to overfit spurious correlations, such as positional bias in benchmark datasets, rather than effectively capturing semantic features. Additionally, while large language models have strong capabilities, they suffer from uncontrollable outputs, leading to mediocre performance in this task.",recent work,ours,a dependency-sensitive language-modeling problem,False,2,1,4,1.3333333333333333
1-22875_9e64c8a0-a8f1-438a-b177-a11aa8e6a2a3,noy.sternlicht@mail.huji.ac.il,"Existing methods for Emotion-Cause Pair Extraction tend to overfit spurious correlations, such as positional bias in benchmark datasets, rather than effectively capturing semantic features. Additionally, while large language models have strong capabilities, they suffer from uncontrollable outputs, leading to mediocre performance in this task.",recent work,random,a generic convolution path,False,2,1,5,1.6666666666666665
1-22875_9e64c8a0-a8f1-438a-b177-a11aa8e6a2a3,noy.sternlicht@mail.huji.ac.il,"Existing methods for Emotion-Cause Pair Extraction tend to overfit spurious correlations, such as positional bias in benchmark datasets, rather than effectively capturing semantic features. Additionally, while large language models have strong capabilities, they suffer from uncontrollable outputs, leading to mediocre performance in this task.",recent work,gpt-4o,cognitive psychology insights,False,2,1,3,1.0
1-22875_9e64c8a0-a8f1-438a-b177-a11aa8e6a2a3,noy.sternlicht@mail.huji.ac.il,"Existing methods for Emotion-Cause Pair Extraction tend to overfit spurious correlations, such as positional bias in benchmark datasets, rather than effectively capturing semantic features. Additionally, while large language models have strong capabilities, they suffer from uncontrollable outputs, leading to mediocre performance in this task.",recent work,positive,recent work,False,2,1,6,2.0
1-22875_9e64c8a0-a8f1-438a-b177-a11aa8e6a2a3,noy.sternlicht@mail.huji.ac.il,"Existing methods for Emotion-Cause Pair Extraction tend to overfit spurious correlations, such as positional bias in benchmark datasets, rather than effectively capturing semantic features. Additionally, while large language models have strong capabilities, they suffer from uncontrollable outputs, leading to mediocre performance in this task.",recent work,mpnet_zero,Multimodal emotion recognition in conversation and multimodal emotion-cause pair extraction (multimodal emotion-cause pair extraction),False,2,1,2,0.6666666666666666
1-22875_9e64c8a0-a8f1-438a-b177-a11aa8e6a2a3,noy.sternlicht@mail.huji.ac.il,"Existing methods for Emotion-Cause Pair Extraction tend to overfit spurious correlations, such as positional bias in benchmark datasets, rather than effectively capturing semantic features. Additionally, while large language models have strong capabilities, they suffer from uncontrollable outputs, leading to mediocre performance in this task.",recent work,sciIE,multimodal emotion-cause pair extraction (MECPE),False,2,1,1,0.3333333333333333
1-30440_f6e4517a-c74e-4884-92e4-b6df15fcb40b,noy.sternlicht@mail.huji.ac.il,"Large Language Models (LLMs) face challenges due to their overreliance on potentially flawed parametric knowledge, leading to hallucinations and inaccuracies, especially with long-tail, domain-specific queries. Additionally, the presence of noisy and irrelevant information in retrieved long-context documents can dilute LLMs' attention, highlighting the need for improved methods to enhance their contextual awareness and robustness.",the supportive role of essential concepts in individuals' reading comprehension,random,patient monitoring,False,3,1,6,3.0
1-30440_f6e4517a-c74e-4884-92e4-b6df15fcb40b,noy.sternlicht@mail.huji.ac.il,"Large Language Models (LLMs) face challenges due to their overreliance on potentially flawed parametric knowledge, leading to hallucinations and inaccuracies, especially with long-tail, domain-specific queries. Additionally, the presence of noisy and irrelevant information in retrieved long-context documents can dilute LLMs' attention, highlighting the need for improved methods to enhance their contextual awareness and robustness.",the supportive role of essential concepts in individuals' reading comprehension,gpt-4o,human cognitive processes,False,3,1,3,1.5
1-30440_f6e4517a-c74e-4884-92e4-b6df15fcb40b,noy.sternlicht@mail.huji.ac.il,"Large Language Models (LLMs) face challenges due to their overreliance on potentially flawed parametric knowledge, leading to hallucinations and inaccuracies, especially with long-tail, domain-specific queries. Additionally, the presence of noisy and irrelevant information in retrieved long-context documents can dilute LLMs' attention, highlighting the need for improved methods to enhance their contextual awareness and robustness.",the supportive role of essential concepts in individuals' reading comprehension,ours,the fusion between distribution of large language models knowledge and distribution of retrieved texts,False,3,1,2,1.0
1-30440_f6e4517a-c74e-4884-92e4-b6df15fcb40b,noy.sternlicht@mail.huji.ac.il,"Large Language Models (LLMs) face challenges due to their overreliance on potentially flawed parametric knowledge, leading to hallucinations and inaccuracies, especially with long-tail, domain-specific queries. Additionally, the presence of noisy and irrelevant information in retrieved long-context documents can dilute LLMs' attention, highlighting the need for improved methods to enhance their contextual awareness and robustness.",the supportive role of essential concepts in individuals' reading comprehension,mpnet_zero,the problem faced by Large Language Models,False,3,1,4,2.0
1-30440_f6e4517a-c74e-4884-92e4-b6df15fcb40b,noy.sternlicht@mail.huji.ac.il,"Large Language Models (LLMs) face challenges due to their overreliance on potentially flawed parametric knowledge, leading to hallucinations and inaccuracies, especially with long-tail, domain-specific queries. Additionally, the presence of noisy and irrelevant information in retrieved long-context documents can dilute LLMs' attention, highlighting the need for improved methods to enhance their contextual awareness and robustness.",the supportive role of essential concepts in individuals' reading comprehension,sciIE,Large-Language model (LLM),False,3,1,5,2.5
1-30440_f6e4517a-c74e-4884-92e4-b6df15fcb40b,noy.sternlicht@mail.huji.ac.il,"Large Language Models (LLMs) face challenges due to their overreliance on potentially flawed parametric knowledge, leading to hallucinations and inaccuracies, especially with long-tail, domain-specific queries. Additionally, the presence of noisy and irrelevant information in retrieved long-context documents can dilute LLMs' attention, highlighting the need for improved methods to enhance their contextual awareness and robustness.",the supportive role of essential concepts in individuals' reading comprehension,positive,the supportive role of essential concepts in individuals' reading comprehension,False,3,1,1,0.5
1-38849_3c50b338-017d-4f6a-8159-dec2b56342d4,noy.sternlicht@mail.huji.ac.il,"Previous works mostly focus on generating better responses but ignore interpretability, which is extremely important for constructing reliable dialogue systems. There is a need to empower systems with better interpretability to enhance the understanding of emotional support responses and establish connections between users and dialogue systems.","the process of identifying, understanding, and regulating emotions",positive,"the process of identifying, understanding, and regulating emotions",False,3,1,1,0.5
1-38849_3c50b338-017d-4f6a-8159-dec2b56342d4,noy.sternlicht@mail.huji.ac.il,"Previous works mostly focus on generating better responses but ignore interpretability, which is extremely important for constructing reliable dialogue systems. There is a need to empower systems with better interpretability to enhance the understanding of emotional support responses and establish connections between users and dialogue systems.","the process of identifying, understanding, and regulating emotions",gpt-4o,cognitive psychology,False,3,1,4,2.0
1-38849_3c50b338-017d-4f6a-8159-dec2b56342d4,noy.sternlicht@mail.huji.ac.il,"Previous works mostly focus on generating better responses but ignore interpretability, which is extremely important for constructing reliable dialogue systems. There is a need to empower systems with better interpretability to enhance the understanding of emotional support responses and establish connections between users and dialogue systems.","the process of identifying, understanding, and regulating emotions",mpnet_zero,Emotion Support Conversation,False,3,1,3,1.5
1-38849_3c50b338-017d-4f6a-8159-dec2b56342d4,noy.sternlicht@mail.huji.ac.il,"Previous works mostly focus on generating better responses but ignore interpretability, which is extremely important for constructing reliable dialogue systems. There is a need to empower systems with better interpretability to enhance the understanding of emotional support responses and establish connections between users and dialogue systems.","the process of identifying, understanding, and regulating emotions",ours,foundational principles of human communication within psychology,False,3,1,2,1.0
1-38849_3c50b338-017d-4f6a-8159-dec2b56342d4,noy.sternlicht@mail.huji.ac.il,"Previous works mostly focus on generating better responses but ignore interpretability, which is extremely important for constructing reliable dialogue systems. There is a need to empower systems with better interpretability to enhance the understanding of emotional support responses and establish connections between users and dialogue systems.","the process of identifying, understanding, and regulating emotions",random,two branch paths from two different multi-scale approaches,False,3,1,5,2.5
1-38849_3c50b338-017d-4f6a-8159-dec2b56342d4,noy.sternlicht@mail.huji.ac.il,"Previous works mostly focus on generating better responses but ignore interpretability, which is extremely important for constructing reliable dialogue systems. There is a need to empower systems with better interpretability to enhance the understanding of emotional support responses and establish connections between users and dialogue systems.","the process of identifying, understanding, and regulating emotions",sciIE,language-based interpretability,False,3,1,6,3.0
1-25266_18243071-a3c6-486e-a546-5cd82af2b259,noy.sternlicht@mail.huji.ac.il,"Enhancing the reasoning capabilities of large language models (LLMs) is a key challenge, particularly for tasks requiring complex, multi-step decision-making. Existing approaches that rely solely on Chain-of-Thought reasoning do not adequately address the need for accurate world state predictions and the exploration of diverse potential actions in complex reasoning tasks.",Humans excel at these tasks by leveraging deliberate planning with an internal world model to simulate the potential outcomes of various actions,positive,Humans excel at these tasks by leveraging deliberate planning with an internal world model to simulate the potential outcomes of various actions,False,4,1,1,0.6666666666666666
1-25266_18243071-a3c6-486e-a546-5cd82af2b259,noy.sternlicht@mail.huji.ac.il,"Enhancing the reasoning capabilities of large language models (LLMs) is a key challenge, particularly for tasks requiring complex, multi-step decision-making. Existing approaches that rely solely on Chain-of-Thought reasoning do not adequately address the need for accurate world state predictions and the exploration of diverse potential actions in complex reasoning tasks.",Humans excel at these tasks by leveraging deliberate planning with an internal world model to simulate the potential outcomes of various actions,ours,the idea of large language model Chain of Thought,False,4,1,5,3.333333333333333
1-25266_18243071-a3c6-486e-a546-5cd82af2b259,noy.sternlicht@mail.huji.ac.il,"Enhancing the reasoning capabilities of large language models (LLMs) is a key challenge, particularly for tasks requiring complex, multi-step decision-making. Existing approaches that rely solely on Chain-of-Thought reasoning do not adequately address the need for accurate world state predictions and the exploration of diverse potential actions in complex reasoning tasks.",Humans excel at these tasks by leveraging deliberate planning with an internal world model to simulate the potential outcomes of various actions,sciIE,multi-step reasoning tasks,False,4,1,3,2.0
1-25266_18243071-a3c6-486e-a546-5cd82af2b259,noy.sternlicht@mail.huji.ac.il,"Enhancing the reasoning capabilities of large language models (LLMs) is a key challenge, particularly for tasks requiring complex, multi-step decision-making. Existing approaches that rely solely on Chain-of-Thought reasoning do not adequately address the need for accurate world state predictions and the exploration of diverse potential actions in complex reasoning tasks.",Humans excel at these tasks by leveraging deliberate planning with an internal world model to simulate the potential outcomes of various actions,gpt-4o,cognitive architectures,False,4,1,2,1.3333333333333333
1-25266_18243071-a3c6-486e-a546-5cd82af2b259,noy.sternlicht@mail.huji.ac.il,"Enhancing the reasoning capabilities of large language models (LLMs) is a key challenge, particularly for tasks requiring complex, multi-step decision-making. Existing approaches that rely solely on Chain-of-Thought reasoning do not adequately address the need for accurate world state predictions and the exploration of diverse potential actions in complex reasoning tasks.",Humans excel at these tasks by leveraging deliberate planning with an internal world model to simulate the potential outcomes of various actions,random,second-order textures,False,4,1,6,4.0
1-25266_18243071-a3c6-486e-a546-5cd82af2b259,noy.sternlicht@mail.huji.ac.il,"Enhancing the reasoning capabilities of large language models (LLMs) is a key challenge, particularly for tasks requiring complex, multi-step decision-making. Existing approaches that rely solely on Chain-of-Thought reasoning do not adequately address the need for accurate world state predictions and the exploration of diverse potential actions in complex reasoning tasks.",Humans excel at these tasks by leveraging deliberate planning with an internal world model to simulate the potential outcomes of various actions,mpnet_zero,multi-step reasoning of Large Language Models,False,4,1,4,2.6666666666666665
1-37407_dea6d3d7-f9e5-4d01-8685-22b3b9a2e164,noy.sternlicht@mail.huji.ac.il,"The study identifies deficiencies in reference-free metrics used for evaluating the compatibility between textual descriptions and images, highlighting issues such as incoherent statements and excessive repetition in generated descriptions. This indicates a need for improved evaluation methods that can better align with human judgment and rectify the shortcomings of existing metrics.",the Cobra Effect,ours,evaluating the quality of text generated by generative Large Language Models(LLMs),False,3,1,5,2.5
1-37407_dea6d3d7-f9e5-4d01-8685-22b3b9a2e164,noy.sternlicht@mail.huji.ac.il,"The study identifies deficiencies in reference-free metrics used for evaluating the compatibility between textual descriptions and images, highlighting issues such as incoherent statements and excessive repetition in generated descriptions. This indicates a need for improved evaluation methods that can better align with human judgment and rectify the shortcomings of existing metrics.",the Cobra Effect,sciIE,low consistency between image and text descriptions,False,3,1,3,1.5
1-37407_dea6d3d7-f9e5-4d01-8685-22b3b9a2e164,noy.sternlicht@mail.huji.ac.il,"The study identifies deficiencies in reference-free metrics used for evaluating the compatibility between textual descriptions and images, highlighting issues such as incoherent statements and excessive repetition in generated descriptions. This indicates a need for improved evaluation methods that can better align with human judgment and rectify the shortcomings of existing metrics.",the Cobra Effect,random,the image-text mapping problem,False,3,1,1,0.5
1-37407_dea6d3d7-f9e5-4d01-8685-22b3b9a2e164,noy.sternlicht@mail.huji.ac.il,"The study identifies deficiencies in reference-free metrics used for evaluating the compatibility between textual descriptions and images, highlighting issues such as incoherent statements and excessive repetition in generated descriptions. This indicates a need for improved evaluation methods that can better align with human judgment and rectify the shortcomings of existing metrics.",the Cobra Effect,mpnet_zero,a text-to-image alignment quality prediction task,False,3,1,4,2.0
1-37407_dea6d3d7-f9e5-4d01-8685-22b3b9a2e164,noy.sternlicht@mail.huji.ac.il,"The study identifies deficiencies in reference-free metrics used for evaluating the compatibility between textual descriptions and images, highlighting issues such as incoherent statements and excessive repetition in generated descriptions. This indicates a need for improved evaluation methods that can better align with human judgment and rectify the shortcomings of existing metrics.",the Cobra Effect,positive,the Cobra Effect,False,3,1,2,1.0
1-37407_dea6d3d7-f9e5-4d01-8685-22b3b9a2e164,noy.sternlicht@mail.huji.ac.il,"The study identifies deficiencies in reference-free metrics used for evaluating the compatibility between textual descriptions and images, highlighting issues such as incoherent statements and excessive repetition in generated descriptions. This indicates a need for improved evaluation methods that can better align with human judgment and rectify the shortcomings of existing metrics.",the Cobra Effect,gpt-4o,human visual perception,False,3,1,6,3.0
1-35139_06200ab8-f2d8-408d-9232-4f2f29c9e2d7,noy.sternlicht@mail.huji.ac.il,"The complex nature of clinical environments presents significant hallucination challenges for large language models (LLMs), hindering their widespread adoption in medical applications. Addressing these hallucination issues is crucial for improving the effectiveness of Medical Information Extraction tasks.",an identify-and-classify process,mpnet_zero,developing large language models in the medical domain to assist clinicians,False,4,1,5,3.333333333333333
1-35139_06200ab8-f2d8-408d-9232-4f2f29c9e2d7,noy.sternlicht@mail.huji.ac.il,"The complex nature of clinical environments presents significant hallucination challenges for large language models (LLMs), hindering their widespread adoption in medical applications. Addressing these hallucination issues is crucial for improving the effectiveness of Medical Information Extraction tasks.",an identify-and-classify process,positive,an identify-and-classify process,False,4,1,3,2.0
1-35139_06200ab8-f2d8-408d-9232-4f2f29c9e2d7,noy.sternlicht@mail.huji.ac.il,"The complex nature of clinical environments presents significant hallucination challenges for large language models (LLMs), hindering their widespread adoption in medical applications. Addressing these hallucination issues is crucial for improving the effectiveness of Medical Information Extraction tasks.",an identify-and-classify process,sciIE,complexity of medical language,False,4,1,4,2.6666666666666665
1-35139_06200ab8-f2d8-408d-9232-4f2f29c9e2d7,noy.sternlicht@mail.huji.ac.il,"The complex nature of clinical environments presents significant hallucination challenges for large language models (LLMs), hindering their widespread adoption in medical applications. Addressing these hallucination issues is crucial for improving the effectiveness of Medical Information Extraction tasks.",an identify-and-classify process,random,mechanical simulation using the finite element method,False,4,1,6,4.0
1-35139_06200ab8-f2d8-408d-9232-4f2f29c9e2d7,noy.sternlicht@mail.huji.ac.il,"The complex nature of clinical environments presents significant hallucination challenges for large language models (LLMs), hindering their widespread adoption in medical applications. Addressing these hallucination issues is crucial for improving the effectiveness of Medical Information Extraction tasks.",an identify-and-classify process,gpt-4o,knowledge distillation techniques,False,4,1,2,1.3333333333333333
1-35139_06200ab8-f2d8-408d-9232-4f2f29c9e2d7,noy.sternlicht@mail.huji.ac.il,"The complex nature of clinical environments presents significant hallucination challenges for large language models (LLMs), hindering their widespread adoption in medical applications. Addressing these hallucination issues is crucial for improving the effectiveness of Medical Information Extraction tasks.",an identify-and-classify process,ours,formulate an EHR question-answering task,False,4,1,1,0.6666666666666666
1-25013_fa771011-68c5-4f3c-8724-0884e85b14e9,noy.sternlicht@mail.huji.ac.il,"The performance of large language models on mathematical problems and reasoning tasks is limited due to the inherent difficulty of these problems and the multi-step nature of their solutions, which complicates the effectiveness of a single prompting technique. This highlights a need for improved approaches that can guide LLMs through varying cognitive processes to reach correct solutions.",Bloom's Taxonomy,positive,Bloom's Taxonomy,False,3,1,1,0.5
1-25013_fa771011-68c5-4f3c-8724-0884e85b14e9,noy.sternlicht@mail.huji.ac.il,"The performance of large language models on mathematical problems and reasoning tasks is limited due to the inherent difficulty of these problems and the multi-step nature of their solutions, which complicates the effectiveness of a single prompting technique. This highlights a need for improved approaches that can guide LLMs through varying cognitive processes to reach correct solutions.",Bloom's Taxonomy,random,static background priors,False,3,1,6,3.0
1-25013_fa771011-68c5-4f3c-8724-0884e85b14e9,noy.sternlicht@mail.huji.ac.il,"The performance of large language models on mathematical problems and reasoning tasks is limited due to the inherent difficulty of these problems and the multi-step nature of their solutions, which complicates the effectiveness of a single prompting technique. This highlights a need for improved approaches that can guide LLMs through varying cognitive processes to reach correct solutions.",Bloom's Taxonomy,ours,well-developed cognitive science,False,3,1,4,2.0
1-25013_fa771011-68c5-4f3c-8724-0884e85b14e9,noy.sternlicht@mail.huji.ac.il,"The performance of large language models on mathematical problems and reasoning tasks is limited due to the inherent difficulty of these problems and the multi-step nature of their solutions, which complicates the effectiveness of a single prompting technique. This highlights a need for improved approaches that can guide LLMs through varying cognitive processes to reach correct solutions.",Bloom's Taxonomy,sciIE,prompt-engineering-based large language models (LLMs),False,3,1,3,1.5
1-25013_fa771011-68c5-4f3c-8724-0884e85b14e9,noy.sternlicht@mail.huji.ac.il,"The performance of large language models on mathematical problems and reasoning tasks is limited due to the inherent difficulty of these problems and the multi-step nature of their solutions, which complicates the effectiveness of a single prompting technique. This highlights a need for improved approaches that can guide LLMs through varying cognitive processes to reach correct solutions.",Bloom's Taxonomy,mpnet_zero,text prompting in Large Language Models,False,3,1,5,2.5
1-25013_fa771011-68c5-4f3c-8724-0884e85b14e9,noy.sternlicht@mail.huji.ac.il,"The performance of large language models on mathematical problems and reasoning tasks is limited due to the inherent difficulty of these problems and the multi-step nature of their solutions, which complicates the effectiveness of a single prompting technique. This highlights a need for improved approaches that can guide LLMs through varying cognitive processes to reach correct solutions.",Bloom's Taxonomy,gpt-4o,cognitive task analysis,False,3,1,2,1.0
