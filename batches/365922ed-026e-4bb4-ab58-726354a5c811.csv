context,anchor,relation,query,k,positive,id,random,mpnet_zero,sciIE,gpt-4o,ours
"The SLAM process requires efficient calculation of numerical derivatives to improve accuracy and convergence speed, which is often hindered by the limitations of large-scale computational graphs. Additionally, there is a need for real-time optimization frameworks that can enhance camera relocalization and robotic navigation in complex environments.",the SLAM process,inspiration,"Background: The SLAM process requires efficient calculation of numerical derivatives to improve accuracy and convergence speed, which is often hindered by the limitations of large-scale computational graphs. Additionally, there is a need for real-time optimization frameworks that can enhance camera relocalization and robotic navigation in complex environments.
Contribution: 'the SLAM process' inspired by ",1,a differentiable function,1-20997_dea92bca-acd1-402e-b51f-dd13c6850fad,an encoder-decoder GNN model,Dynamic SLAM,large-scale SLAM reconstructions,graph neural networks,a continuous optimization process
"The effectiveness of query-based end-to-end instance segmentation methods diminishes significantly when confronted with limited training data, as they rely on substantial data volumes to effectively train the pivotal queries and kernels necessary for acquiring localization and shape priors. This limitation highlights the need for improved methods that can enhance performance in low-data regimes.",unsupervised pre-training in low-data regimes,inspiration,"Background: The effectiveness of query-based end-to-end instance segmentation methods diminishes significantly when confronted with limited training data, as they rely on substantial data volumes to effectively train the pivotal queries and kernels necessary for acquiring localization and shape priors. This limitation highlights the need for improved methods that can enhance performance in low-data regimes.
Contribution: 'unsupervised pre-training in low-data regimes' inspired by ",2,the recently successful prompting technique,2-21054_a9a52e87-b684-470b-a6c5-28cb7ae9414b,eye tracking,advanced instance segmentation methods,instance segmentation,contrastive learning,emerging unsupervised reconstruction techniques based on implicit neural representation
"The effective extraction of movement patterns and travel purposes from spatio-temporal trajectories is challenging due to limitations in model capacity and the quality and scale of trajectory datasets. Standard large language models are not designed to handle the unique spatio-temporal features of trajectories, which hinders their ability to extract relevant information effectively.",spatio-temporal trajectories,inspiration,"Background: The effective extraction of movement patterns and travel purposes from spatio-temporal trajectories is challenging due to limitations in model capacity and the quality and scale of trajectory datasets. Standard large language models are not designed to handle the unique spatio-temporal features of trajectories, which hinders their ability to extract relevant information effectively.
Contribution: 'spatio-temporal trajectories' inspired by ",2,sentences,2-6390_2a922e5d-ce75-454d-8e32-b94531a98a1d,textual semantic features,"visualizing complex traffic environments and historical trajectory information of traffic participants into image prompts -- Transportation Context Map (TC-Map), accompanied by corresponding text prompts",spatial-temporal data,graph neural networks,a sequence of temporal graphs
"Previous studies in multi-modal learning have primarily focused on either inter-modality or intra-modality dependencies in isolation, which may not provide optimal results. This highlights a gap in the existing approaches that do not adequately capture the interactions between different modalities and their relationships to the target label.",Supervised multi-modal learning,inspiration,"Background: Previous studies in multi-modal learning have primarily focused on either inter-modality or intra-modality dependencies in isolation, which may not provide optimal results. This highlights a gap in the existing approaches that do not adequately capture the interactions between different modalities and their relationships to the target label.
Contribution: 'Supervised multi-modal learning' inspired by ",1,generative models,1-292_71d8b1de-8d5c-491c-ac24-cdfc8d80baee,model-,multi-modal learning,multi-modality learning,attention mechanisms,a Weakly Supervised Cross-modality Contrastive Learning problem
"Large language models (LLMs) struggle to efficiently and effectively integrate a large amount of new experiences after pre-training, often leading to issues such as catastrophic forgetting. Existing retrieval-augmented generation methods do not adequately address the need for deeper and more efficient knowledge integration over new experiences.",Large language models,inspiration,"Background: Large language models (LLMs) struggle to efficiently and effectively integrate a large amount of new experiences after pre-training, often leading to issues such as catastrophic forgetting. Existing retrieval-augmented generation methods do not adequately address the need for deeper and more efficient knowledge integration over new experiences.
Contribution: 'Large language models' inspired by ",1,the hippocampal indexing theory of human long-term memory,1-22754_bedeb6c2-8c39-419a-a266-853073a26761,clinicians' decision-making processes for hemoglobin level/anemia degree prediction,"Contrary to human language learning, recent advancements in large language models have primarily adopted a non-interactive training paradigm, and refined pre-trained models through feedback afterward",long-context retrieval augmented generation,the memory consolidation process of the human brain,the retrieve-then-generate paradigm of Retrieval-augmented generation
"Current methods for scene text synthesis lack effective character-level guidance during training and struggle to adapt to diverse font styles, leading to issues such as character distortion, repetition, and absence, particularly in polystylistic scenarios. This highlights a need for improved training processes that can better handle these challenges and enhance the model's attention to character-level details.",Scene text synthesis,inspiration,"Background: Current methods for scene text synthesis lack effective character-level guidance during training and struggle to adapt to diverse font styles, leading to issues such as character distortion, repetition, and absence, particularly in polystylistic scenarios. This highlights a need for improved training processes that can better handle these challenges and enhance the model's attention to character-level details.
Contribution: 'Scene text synthesis' inspired by ",2,the diffusion training process,2-19608_6128316a-0c8c-4a77-a599-707f93b72316,CNN,text-to-image generation,text-to-image generation,GANs with character-level attention,a constrained text generation problem
"The limited controllability of large language models (LLMs) poses a significant challenge for downstream applications, particularly in the context of language generation. Existing LLMs rely on fully auto-regressive generation, which does not adequately address the intricacies of decision-making involved in language processing.",a decision-making process,inspiration,"Background: The limited controllability of large language models (LLMs) poses a significant challenge for downstream applications, particularly in the context of language generation. Existing LLMs rely on fully auto-regressive generation, which does not adequately address the intricacies of decision-making involved in language processing.
Contribution: 'a decision-making process' inspired by ",2,"the neural mechanisms of the human brain, specifically Broca's and Wernicke's areas, which are crucial for language generation and comprehension",2-32037_336b2c18-9823-4bfc-92e2-c13a60676a01,a 3D point subset generative problem conditioned on input frames,the language generation capabilities of multimodal Large Language Models,generative large language model (LLM),human cognitive decision-making,an iterative Markov decision process
"Previous methods for drag-based image editing often suffer from long processing times and low success rates, which limits their practical application. Additionally, these methods typically rely on time-consuming latent optimization or gradient-based guidance during inference, indicating a need for more efficient approaches that can maintain high quality and accuracy.",drag-based image editing,inspiration,"Background: Previous methods for drag-based image editing often suffer from long processing times and low success rates, which limits their practical application. Additionally, these methods typically rely on time-consuming latent optimization or gradient-based guidance during inference, indicating a need for more efficient approaches that can maintain high quality and accuracy.
Contribution: 'drag-based image editing' inspired by ",1,a conditional generation task,1-10348_21c643de-513e-4fb6-a03e-5c372bf2c379,model-free updates,DragGAN in image generation,drag-based editing,neural radiance fields,recent diffusion based image editing techniques
"The challenges of acquiring fMRI-image pairs and the variability among individuals significantly hinder the effectiveness of traditional brain decoding methods, which typically rely on a per-subject-per-model paradigm. This limitation necessitates the exploration of new approaches that can effectively utilize limited data while addressing the issues of overfitting and inadequate guidance during training.",few-shot brain decoding,inspiration,"Background: The challenges of acquiring fMRI-image pairs and the variability among individuals significantly hinder the effectiveness of traditional brain decoding methods, which typically rely on a per-subject-per-model paradigm. This limitation necessitates the exploration of new approaches that can effectively utilize limited data while addressing the issues of overfitting and inadequate guidance during training.
Contribution: 'few-shot brain decoding' inspired by ",2,the hemodynamic response function,2-13317_f57406c6-1e89-4e83-8107-b7384e1ee831,Poisson-based seamless image cloning,brain representation that is extracted from the fMRI,brain decoding tasks,meta-learning techniques,recent work in few-shot learning
"Current methods in knowledge distillation provide equal weight to task-specific and knowledge distillation losses, which leads to suboptimal performance. There is a need for a more effective approach that can adaptively optimize these weights to improve the distillation process.",knowledge distillation,inspiration,"Background: Current methods in knowledge distillation provide equal weight to task-specific and knowledge distillation losses, which leads to suboptimal performance. There is a need for a more effective approach that can adaptively optimize these weights to improve the distillation process.
Contribution: 'knowledge distillation' inspired by ",2,curriculum learning,2-3733_980f6023-43d7-4bc4-99be-9a28052de3d3,human reasoning during driving,Spearman correlation coefficients-based Knowledge Distillation loss,Adaptive Knowledge Distillation,adaptive learning algorithms,a bilevel optimization problem
