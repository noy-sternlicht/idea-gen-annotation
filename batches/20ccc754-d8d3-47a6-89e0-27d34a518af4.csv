context,anchor,relation,query,k,positive,id,random,mpnet_zero,sciIE,gpt-4o,ours
"Existing hyperspectral target detection methods are limited by their reliance on per-pixel binary classification, which restricts their ability to effectively represent features of point targets that occupy less than one pixel. This highlights a need for improved object-level prediction capabilities in hyperspectral point target detection.",point object detection,inspiration,"Background: Existing hyperspectral target detection methods are limited by their reliance on per-pixel binary classification, which restricts their ability to effectively represent features of point targets that occupy less than one pixel. This highlights a need for improved object-level prediction capabilities in hyperspectral point target detection.
Contribution: 'point object detection' inspired by ",1,a one-to-many set prediction problem,1-33313_69d0d45f-bf27-4c08-bb39-c114decb1119,symbolic systems,Hyperspectral image classification,simulated hyperSpectral Point Object Detection benchmark,YOLO (You Only Look Once) architecture,two-stage Object Detection in computer vision
"Few-shot learning faces challenges in effectively leveraging both visual and textual knowledge to generalize from seen categories to novel scenarios. Existing methods struggle to balance the general representation provided by class names with the specific information captured in images, leading to potential biases that hinder the recognition of novel classes.",Few-shot Learning,inspiration,"Background: Few-shot learning faces challenges in effectively leveraging both visual and textual knowledge to generalize from seen categories to novel scenarios. Existing methods struggle to balance the general representation provided by class names with the specific information captured in images, leading to potential biases that hinder the recognition of novel classes.
Contribution: 'Few-shot Learning' inspired by ",2,a human intuition,2-41374_08e426b5-6388-4270-826a-20743c95e068,Safe MARL,recent work in few-shot learning,few-shot classification,multimodal learning,recent vision-language pre-trained models such as CLIP in zero-shot classification
"Current vision models are heavily biased towards texture, which can lead to catastrophic forgetting when adapting from one domain distribution to another. This highlights the need for methodologies that can effectively manage the adaptation process while preserving important features across evolving target domains.",vision models,inspiration,"Background: Current vision models are heavily biased towards texture, which can lead to catastrophic forgetting when adapting from one domain distribution to another. This highlights the need for methodologies that can effectively manage the adaptation process while preserving important features across evolving target domains.
Contribution: 'vision models' inspired by ",1,the human visual system's adeptness at processing both shape and texture according to the famous Trichromatic Theory,1-25284_691cd5b2-71a4-48f2-bc7f-451b411e6967,a channel-wise next curve shape prediction problem,Universal Domain Adaptation,adapting vision-langage models,contrastive learning,Human-like Adaptability through Compositionality
"The numerical solutions provided by existing methods for solving partial differential equations (PDEs) often lack precision and interpretability compared to symbolic solutions. Additionally, there is a challenge in fitting high-frequency and steeply changing functions, which current approaches struggle to address.",Solving partial differential equations in Euclidean space,inspiration,"Background: The numerical solutions provided by existing methods for solving partial differential equations (PDEs) often lack precision and interpretability compared to symbolic solutions. Additionally, there is a challenge in fitting high-frequency and steeply changing functions, which current approaches struggle to address.
Contribution: 'Solving partial differential equations in Euclidean space' inspired by ",1,deep learning,1-10572_5c49b0ab-b034-470e-a651-a626dc66a1f7,class embeddings as anchors,Data-driven techniques for solving partial differential equations,numerical solution of PDEs,neural networks,solve elliptic partial differential equations
"Current semi-supervised learning methods are limited by their reliance on heuristics or predefined rules for generating pseudo-labels, which restricts their ability to effectively utilize unlabeled data. Additionally, these methods often exploit loss functions and regularization techniques within standard norms, indicating a need for more adaptive and innovative approaches to enhance model performance, particularly when labeled data is scarce.",Reinforcement Learning,inspiration,"Background: Current semi-supervised learning methods are limited by their reliance on heuristics or predefined rules for generating pseudo-labels, which restricts their ability to effectively utilize unlabeled data. Additionally, these methods often exploit loss functions and regularization techniques within standard norms, indicating a need for more adaptive and innovative approaches to enhance model performance, particularly when labeled data is scarce.
Contribution: 'Reinforcement Learning' inspired by ",1,a one-armed bandit problem,1-42227_2ae44ab8-0b14-492e-a91d-5ba6f72c1de7,segment-level recurrence for storage of task specific information distributed over a long context,semi-supervised learning leveraging limited labeled data and a large amount of unlabeled data,semi-supervised learning,human learning processes,Traditional semi-supervised learning
"Accurate retinal vessel segmentation is essential for the early detection of retinal diseases, yet existing pixel-wise classification approaches are biased and fail to account for the uncertainty inherent in human annotations, particularly for thin vessels. This highlights a need for improved methodologies that can better handle annotation uncertainty and enhance segmentation performance across diverse datasets.",segmenting vessels automatically,inspiration,"Background: Accurate retinal vessel segmentation is essential for the early detection of retinal diseases, yet existing pixel-wise classification approaches are biased and fail to account for the uncertainty inherent in human annotations, particularly for thin vessels. This highlights a need for improved methodologies that can better handle annotation uncertainty and enhance segmentation performance across diverse datasets.
Contribution: 'segmenting vessels automatically' inspired by ",2,an image-level regression,2-419_42245eec-3db7-4ff4-8a1b-01d5790d5c43,checkerboard calibration patterns,"humans, given a few exemplars (with corresponding labels), are able to segment different medical images even without extensive domain-specific clinical training",medical segmentation decathlon datasets,Bayesian deep learning,a probabilistic inference problem
"Long-context modeling poses significant challenges for transformer-based large language models due to the quadratic complexity of the self-attention mechanism and issues with length extrapolation from pretraining on short inputs. Existing methods often require sequential access to documents, which may not be necessary for goal-oriented reading, indicating a need for more efficient strategies in processing long documents.",transformers,inspiration,"Background: Long-context modeling poses significant challenges for transformer-based large language models due to the quadratic complexity of the self-attention mechanism and issues with length extrapolation from pretraining on short inputs. Existing methods often require sequential access to documents, which may not be necessary for goal-oriented reading, indicating a need for more efficient strategies in processing long documents.
Contribution: 'transformers' inspired by ",2,human reading behaviors and existing empirical observations,2-34616_d5a50cb3-3804-46c3-b231-cbc888644720,an Intermediary Matching module,a Transformer-XL large language model,large-context Transformers,Hierarchical processing in the human brain,how humans interactively read long documents
"Existing transfer attacks suffer from either weak transferability or expensive computation, highlighting a need for more efficient methods that can generate highly transferable adversarial examples without significant computational costs. Additionally, the challenge of resolving computationally intensive inner minimization problems affects overall transferability, indicating a gap in current methodologies.",craft adversarial examples,inspiration,"Background: Existing transfer attacks suffer from either weak transferability or expensive computation, highlighting a need for more efficient methods that can generate highly transferable adversarial examples without significant computational costs. Additionally, the challenge of resolving computationally intensive inner minimization problems affects overall transferability, indicating a gap in current methodologies.
Contribution: 'craft adversarial examples' inspired by ",2,a max-min bi-level optimization problem,2-21347_f7a7cebb-d2fe-449c-bcf2-e642a4f5f981,Pearl's structural causal models,Adversarial Example Soups,adversarial perturbations,evolutionary algorithms,a human-like optimization process
"The limited controllability of large language models (LLMs) poses a significant challenge for downstream applications, particularly in the context of language generation. Existing LLMs rely on fully auto-regressive generation, which does not adequately address the intricacies of decision-making involved in language processing.",a decision-making process,inspiration,"Background: The limited controllability of large language models (LLMs) poses a significant challenge for downstream applications, particularly in the context of language generation. Existing LLMs rely on fully auto-regressive generation, which does not adequately address the intricacies of decision-making involved in language processing.
Contribution: 'a decision-making process' inspired by ",1,"the neural mechanisms of the human brain, specifically Broca's and Wernicke's areas, which are crucial for language generation and comprehension",1-32037_336b2c18-9823-4bfc-92e2-c13a60676a01,auxiliary objective,Text generation in Large Language Models,Large Language Model,human cognitive decision-making,a one-step Markov decision process
"The theoretical justification of performance improvements in previous context-based approaches remains underexplored, particularly regarding the optimization framework that may ignore the variation of the task representation, potentially violating monotonicity in performance improvements. This highlights a need to address the issue of task representation shift to ensure guaranteed performance enhancements in offline meta reinforcement learning.",Offline meta reinforcement learning,inspiration,"Background: The theoretical justification of performance improvements in previous context-based approaches remains underexplored, particularly regarding the optimization framework that may ignore the variation of the task representation, potentially violating monotonicity in performance improvements. This highlights a need to address the issue of task representation shift to ensure guaranteed performance enhancements in offline meta reinforcement learning.
Contribution: 'Offline meta reinforcement learning' inspired by ",2,the return discrepancy scheme in the model-based reinforcement learning field,2-33355_fc5141c0-059a-4e6f-a74b-12204bf6ebcb,pre-trained on an extensive corpus of biomedical literature,"a zero-shot meta-reinforcement learning setting with an unknown task distribution and a Bayesian regret minimization objective, where the unobserved tasks are encoded as parameters with an unknown prior",gradient-based meta-learning,Bayesian inference,in-context learning in natural language processing
