context,anchor,relation,query,k,positive,id,arxiv_categories,is_cross_domain,random,mpnet_zero,sciIE,gpt-4o,ours
"Existing RAG models often treat LLMs as passive recipients of information, which can lead to interference from noisy retrieved content. This approach can result in conflicts between external knowledge and parametric memory, highlighting the need for improved engagement and learning from retrieved evidence.",Large Language Models,inspiration,"Background: Existing RAG models often treat LLMs as passive recipients of information, which can lead to interference from noisy retrieved content. This approach can result in conflicts between external knowledge and parametric memory, highlighting the need for improved engagement and learning from retrieved evidence.
Contribution: 'Large Language Models' inspired by ",1,human learning behavior,1-447_47f54a5c-2d5a-405b-817f-76d89fc256ae,['cs.cl'],True,a biomedical-specialized pre-trained language model,Large Language Models' knowledge recall mechanisms,Large-Language model (LLM),interactive learning systems,"Anderson's ACT-R (Adaptive Control of Thought-Rational), a cognitive architecture modeling human information access and memory dynamics"
"Large language models (LLMs) often struggle to provide up-to-date information due to their one-time training and the constantly evolving nature of the world. Existing approaches to keep LLMs current face difficulties in extracting stored knowledge, highlighting a need for improved methods of knowledge acquisition from raw documents.",improve an LLM's ability to effectively acquire new knowledge from raw documents,inspiration,"Background: Large language models (LLMs) often struggle to provide up-to-date information due to their one-time training and the constantly evolving nature of the world. Existing approaches to keep LLMs current face difficulties in extracting stored knowledge, highlighting a need for improved methods of knowledge acquisition from raw documents.
Contribution: 'improve an LLM's ability to effectively acquire new knowledge from raw documents' inspired by ",1,the remarkable success of the Feynman Technique in efficient human learning,1-31947_b1f88262-1a96-403f-869a-81fc0a4265a7,['cs.cl'],True,large foundation models,the fusion between distribution of large language models knowledge and distribution of retrieved texts,open-source large language models (LLMs),neuroscience-inspired memory consolidation,"neuroscience, where the human brain often sheds outdated information to improve the retention of crucial knowledge and facilitate the acquisition of new information"
"Model attribution for LLM-generated disinformation is challenging due to the human-like quality of the disinformation produced and the diversity in prompting methods, which complicates accurate source attribution. An effective attribution model must be invariant to domain-specific features and proficient in identifying originating models across various scenarios, reflecting real-world detection challenges.",Model attribution for LLM-generated disinformation,inspiration,"Background: Model attribution for LLM-generated disinformation is challenging due to the human-like quality of the disinformation produced and the diversity in prompting methods, which complicates accurate source attribution. An effective attribution model must be invariant to domain-specific features and proficient in identifying originating models across various scenarios, reflecting real-world detection challenges.
Contribution: 'Model attribution for LLM-generated disinformation' inspired by ",1,a domain generalization problem,1-641_e3d9632c-90a7-45f0-a4dc-e89908811948,['cs.cl'],True,a self-evolving framework,independent disinformation generation characteristics of various large language models,Detecting Misinformation by Integrating Intent featuRes (DM-INTER),forensic linguistics,the attribution task
"Modern Large Language Models (LLMs) exhibit a performance gap in basic tasks like relation and event extraction, primarily due to the imprecision of existing evaluation metrics and the incompleteness of evaluation benchmarks caused by restrictive human annotation schemas. These issues lead to an underestimation of LLM performances and highlight the need for improved evaluation methods that can better assess semantic consistency and address benchmark limitations.",evaluation of Large Language Models,inspiration,"Background: Modern Large Language Models (LLMs) exhibit a performance gap in basic tasks like relation and event extraction, primarily due to the imprecision of existing evaluation metrics and the incompleteness of evaluation benchmarks caused by restrictive human annotation schemas. These issues lead to an underestimation of LLM performances and highlight the need for improved evaluation methods that can better assess semantic consistency and address benchmark limitations.
Contribution: 'evaluation of Large Language Models' inspired by ",1,the principles in subjective question correction,1-23261_dcdf3bfd-5fb5-4416-bf14-0992a328cd59,['cs.cl'],True,human flexibility and reasoning,the success of large language models in NLP,fine-tuned large language models (LLMs),human cognitive evaluation,human evaluation
"Large Language Models (LLMs) face challenges due to their overreliance on potentially flawed parametric knowledge, leading to hallucinations and inaccuracies, especially with long-tail, domain-specific queries. Additionally, the presence of noisy and irrelevant information in retrieved long-context documents can dilute LLMs' attention, highlighting the need for improved methods to enhance their contextual awareness and robustness.",improve the robustness and contextual awareness of Large Language Models,inspiration,"Background: Large Language Models (LLMs) face challenges due to their overreliance on potentially flawed parametric knowledge, leading to hallucinations and inaccuracies, especially with long-tail, domain-specific queries. Additionally, the presence of noisy and irrelevant information in retrieved long-context documents can dilute LLMs' attention, highlighting the need for improved methods to enhance their contextual awareness and robustness.
Contribution: 'improve the robustness and contextual awareness of Large Language Models' inspired by ",1,the supportive role of essential concepts in individuals' reading comprehension,1-30440_f6e4517a-c74e-4884-92e4-b6df15fcb40b,['cs.cl'],True,patient monitoring,the problem faced by Large Language Models,Large-Language model (LLM),human cognitive processes,the fusion between distribution of large language models knowledge and distribution of retrieved texts
