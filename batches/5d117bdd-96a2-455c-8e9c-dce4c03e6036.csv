context,anchor,relation,query,k,positive,id,random,mpnet_zero,sciIE,gpt-4o,ours
"The study highlights the inherent limitations of ordinal benchmark systems in machine learning, particularly their sensitivity to the inclusion of irrelevant models, which poses challenges in achieving stable and reliable model rankings. Additionally, it identifies a trade-off between diversity and stability in multi-task benchmarks, indicating a need for improved quantitative measures to assess these characteristics effectively.",multi-task benchmarks in machine learning,inspiration,"Background: The study highlights the inherent limitations of ordinal benchmark systems in machine learning, particularly their sensitivity to the inclusion of irrelevant models, which poses challenges in achieving stable and reliable model rankings. Additionally, it identifies a trade-off between diversity and stability in multi-task benchmarks, indicating a need for improved quantitative measures to assess these characteristics effectively.
Contribution: 'multi-task benchmarks in machine learning' inspired by ",2,social choice theory,2-14414_e69b33e5-9e86-422f-925e-908193850145,high-quality textual,a framework consisting of two modules designed to effectively store and reuse task vectors to elicit the diverse capabilities of models without additional training or inference tokens,artificial intelligence benchmark,cognitive neuroscience,the concept of comparison
"Leveraging pretrained text-to-image diffusion models for video editing presents significant challenges, particularly in maintaining temporal consistency amidst strong nonrigid motion. Existing methods that enforce temporal consistency often struggle with these complexities, highlighting a need for more effective approaches in this area.",Text-to-image (T2I) diffusion models,inspiration,"Background: Leveraging pretrained text-to-image diffusion models for video editing presents significant challenges, particularly in maintaining temporal consistency amidst strong nonrigid motion. Existing methods that enforce temporal consistency often struggle with these complexities, highlighting a need for more effective approaches in this area.
Contribution: 'Text-to-image (T2I) diffusion models' inspired by ",2,spatiotemporal slices of natural videos exhibit similar characteristics to natural images,2-11637_e1962592-3ec5-44ea-b48c-d0d95fb409b1,Generative AI models,pre-trained text-to-image diffusion models,pre-trained text to image diffusion model,optical flow techniques,recent advancements in video diffusion models
"The increasing demand for dynamic 3D assets in design and gaming applications has highlighted the limitations of previous methods, which often result in defects such as over-saturation and the Janus problem. Additionally, practical challenges like dramatic temporal inconsistency, inter-frame geometry and texture diversity, and semantic defects in video generation results necessitate the development of more effective solutions.",optimize a 4D representation by explicitly generating multi-view videos from one input image,inspiration,"Background: The increasing demand for dynamic 3D assets in design and gaming applications has highlighted the limitations of previous methods, which often result in defects such as over-saturation and the Janus problem. Additionally, practical challenges like dramatic temporal inconsistency, inter-frame geometry and texture diversity, and semantic defects in video generation results necessitate the development of more effective solutions.
Contribution: 'optimize a 4D representation by explicitly generating multi-view videos from one input image' inspired by ",2,recent progress of video diffusion models,2-773_4ff647e6-3a35-409f-b617-b2d4cad0e4ef,causality theory,4D content creation,depth-conditioned video generation,neural radiance fields (NeRFs),synthesizing realistic novel views using Neural Radiance Fields
"Transformer-based large language models are limited by their context window, which restricts their ability to attend to all input tokens. Previous models have struggled with memory architectures that are not effective in selecting and filtering information, highlighting a need for improved long-context processing capabilities.",Transformer-based large language models,inspiration,"Background: Transformer-based large language models are limited by their context window, which restricts their ability to attend to all input tokens. Previous models have struggled with memory architectures that are not effective in selecting and filtering information, highlighting a need for improved long-context processing capabilities.
Contribution: 'Transformer-based large language models' inspired by ",2,humans are good at learning and self-adjustment,2-37488_d9edf025-436f-4199-89aa-885bc3dc757d,the notion of actionability in explainable AI research,state-of-the-art Large Language Models,Large Language Model,hierarchical attention mechanisms,attention algorithm in Transformer and human memory mechanisms
"Few-shot segmentation faces challenges due to the limitations of labeling information for unseen classes, as previous approaches often rely on high-level feature maps that exhibit coarse granularity and category bias, leading to poor generalization. This highlights a need for more reliable guidance mechanisms that can enhance model generalization in the context of few-shot learning.",few-shot segmentation,inspiration,"Background: Few-shot segmentation faces challenges due to the limitations of labeling information for unseen classes, as previous approaches often rely on high-level feature maps that exhibit coarse granularity and category bias, leading to poor generalization. This highlights a need for more reliable guidance mechanisms that can enhance model generalization in the context of few-shot learning.
Contribution: 'few-shot segmentation' inspired by ",1,the visual-text alignment capacity,1-35062_c20de314-9932-44f2-861b-2048712e12b5,implicit,few-shot semantic segmentation,few-shot learning and segmentation,meta-learning techniques,weak-to-strong generalization
"Unsupervised domain adaptation for monocular depth estimation has been explored to reduce reliance on large annotated datasets, but this often requires training multiple models or complex protocols. The need for a simpler and more effective approach that can operate with only source domain ground truth labels is evident, as demonstrated by the challenges faced in prior work.",unsupervised domain adaptation for monocular depth estimation,inspiration,"Background: Unsupervised domain adaptation for monocular depth estimation has been explored to reduce reliance on large annotated datasets, but this often requires training multiple models or complex protocols. The need for a simpler and more effective approach that can operate with only source domain ground truth labels is evident, as demonstrated by the challenges faced in prior work.
Contribution: 'unsupervised domain adaptation for monocular depth estimation' inspired by ",1,a consistency-based semi-supervised learning problem,1-21426_67fc75b7-c12d-46c5-988a-a2dbf34a332a,the neural ODE approach,unsupervised domain adaptation,monocular depth estimation network,self-supervised learning,an unsupervised domain adaptation problem
"Traditional methods for data manipulation in data lakes require extensive human efforts for training data collection and model tuning, while recent approaches using Large Language Models still necessitate costly customized designs for specific tasks, failing to meet the demands of big data platforms. This highlights the need for an automatic and general solution to efficiently address various data manipulation tasks.",design an automatic and general solution to tackle with data manipulation tasks,inspiration,"Background: Traditional methods for data manipulation in data lakes require extensive human efforts for training data collection and model tuning, while recent approaches using Large Language Models still necessitate costly customized designs for specific tasks, failing to meet the demands of big data platforms. This highlights the need for an automatic and general solution to efficiently address various data manipulation tasks.
Contribution: 'design an automatic and general solution to tackle with data manipulation tasks' inspired by ",1,the cross-task generality of Large Language Models on NLP tasks,1-25224_0175991f-5795-4386-bdbf-898da3192846,Vision-Language Pre-training models,data transformation strategies from language,data engine,self-supervised learning,the rise of large language models in various AI applications
"The need for effective dimension reduction techniques is highlighted by the challenges posed by high-dimensional data, which necessitates discovering low rank approximations to preserve the local structure of the data. Additionally, the superiority of low dimensional embeddings over original data underscores the importance of developing models that can efficiently handle these complexities while ensuring non-negativity constraints.",Few-shot Learning,inspiration,"Background: The need for effective dimension reduction techniques is highlighted by the challenges posed by high-dimensional data, which necessitates discovering low rank approximations to preserve the local structure of the data. Additionally, the superiority of low dimensional embeddings over original data underscores the importance of developing models that can efficiently handle these complexities while ensuring non-negativity constraints.
Contribution: 'Few-shot Learning' inspired by ",2,Referring back to the original text in the course of hierarchical learning is a common human trait that ensures the right direction of learning,2-25207_55d2d3cd-f381-438e-8f9e-37abf3eb264c,the dynamic relationship between giraffes and acacias on the African Savannah,few-shot learning frameworks,few-shot learning,Bayesian inference,"pruning, tensor decomposition, and annealing-based matrix factorization"
"The study addresses decision-aiding problems characterized by multiple objectives and uncertain states of the world, where no preferential information is available to construct importance parameters for the criteria. This context highlights the need for effective support in decision-making that considers the likelihoods of different states and their impact on citizens' choices.",decision-aiding problems that involve multiple objectives and uncertain states of the world,inspiration,"Background: The study addresses decision-aiding problems characterized by multiple objectives and uncertain states of the world, where no preferential information is available to construct importance parameters for the criteria. This context highlights the need for effective support in decision-making that considers the likelihoods of different states and their impact on citizens' choices.
Contribution: 'decision-aiding problems that involve multiple objectives and uncertain states of the world' inspired by ",1,the capability approach,1-14462_d2b41b7b-54ea-4c68-91eb-688e3b7d7d49,the Riemannian geometry of the manifold of symmetric positive definite matrices,the decision-making problem,decision-making under uncertainty,robust optimization,principles of rational decision-making
Imitation learning often faces challenges related to the brittleness and instability of training processes. There is a need for more robust and smoother reward signals to enhance policy learning in this domain.,imitation learning,inspiration,"Background: Imitation learning often faces challenges related to the brittleness and instability of training processes. There is a need for more robust and smoother reward signals to enhance policy learning in this domain.
Contribution: 'imitation learning' inspired by ",2,adversarial learning,2-4985_dee24a07-87b6-4b39-addb-a9780539ef7b,the Deep Deterministic Policy Gradient algorithm,how inverse reinforcement learning trains a policy based on the reward function learned from expert demonstrations,imitation learning,inverse reinforcement learning,shaping reward selection
