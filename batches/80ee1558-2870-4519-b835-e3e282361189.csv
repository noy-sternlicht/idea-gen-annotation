context,anchor,relation,query,k,positive,id,random,mpnet_zero,sciIE,gpt-4o,ours
"Existing LLM agents struggle with creative tasks that have open goals and abstract criteria, as they lack the ability to bridge the gap between these tasks and do not receive feedback for self-improvement. This highlights a need for techniques that can enhance the performance of agents in creative building tasks, particularly in environments like Minecraft.",creative agents,inspiration,"Background: Existing LLM agents struggle with creative tasks that have open goals and abstract criteria, as they lack the ability to bridge the gap between these tasks and do not receive feedback for self-improvement. This highlights a need for techniques that can enhance the performance of agents in creative building tasks, particularly in environments like Minecraft.
Contribution: 'creative agents' inspired by ",1,human design practices,1-28821_b0b7ffdc-69f8-48f7-8f7e-ebd756a29ce8,the Dynamic Dif-Fusion module,enhance LLM creativity,LLM-based agents,human creativity and problem-solving,human creativity
"The challenge of policy learning from expert demonstrations is compounded by issues such as distributional shift, environment stochasticity, and compounding errors, which can lead to policy failure upon deployment. Additionally, existing approaches like adversarial imitation learning require on-policy training samples for stability, which can be inefficient and result in high sample complexity in realistic domains.",policy learning from expert demonstrations,inspiration,"Background: The challenge of policy learning from expert demonstrations is compounded by issues such as distributional shift, environment stochasticity, and compounding errors, which can lead to policy failure upon deployment. Additionally, existing approaches like adversarial imitation learning require on-policy training samples for stability, which can be inefficient and result in high sample complexity in realistic domains.
Contribution: 'policy learning from expert demonstrations' inspired by ",2,"a fine-tuning problem, rather than a pure reinforcement learning one",2-18587_b264fbf0-cf08-475d-8980-bfe8b35a75b6,information retrieval systems,Adversarial Imitation Learning,Generative Adversarial imitation learning (GAIL),inverse reinforcement learning,an imitation-learning problem
"Traditional control strategies for quadrupedal robots often enforce fixed postures, which can minimize natural body movements and overlook the dynamical advantages of natural locomotion. This study addresses the need for more efficient and stable robotic locomotion by embracing the natural dynamics of quadrupedal movement, particularly in asymmetrical gaits like bounding.",quadrupedal locomotion,inspiration,"Background: Traditional control strategies for quadrupedal robots often enforce fixed postures, which can minimize natural body movements and overlook the dynamical advantages of natural locomotion. This study addresses the need for more efficient and stable robotic locomotion by embracing the natural dynamics of quadrupedal movement, particularly in asymmetrical gaits like bounding.
Contribution: 'quadrupedal locomotion' inspired by ",2,natural dynamics and underactuated robotics principles,2-22155_80861036-843f-4acf-8dd8-eeca31242c9e,supervised contrastive learning,the natural gait transition mechanism of quadrupeds,dexterous quadrupedal robot,Cheetah locomotion,"the natural locomotion behaviors of humans and animals, which adapt their gaits to minimize energy consumption"
"Large Language Models (LLMs) face challenges due to their overreliance on potentially flawed parametric knowledge, leading to hallucinations and inaccuracies, especially with long-tail, domain-specific queries. Additionally, the presence of noisy and irrelevant information in retrieved long-context documents can dilute LLMs' attention, highlighting the need for improved methods to enhance their contextual awareness and robustness.",improve the robustness and contextual awareness of Large Language Models,inspiration,"Background: Large Language Models (LLMs) face challenges due to their overreliance on potentially flawed parametric knowledge, leading to hallucinations and inaccuracies, especially with long-tail, domain-specific queries. Additionally, the presence of noisy and irrelevant information in retrieved long-context documents can dilute LLMs' attention, highlighting the need for improved methods to enhance their contextual awareness and robustness.
Contribution: 'improve the robustness and contextual awareness of Large Language Models' inspired by ",1,the supportive role of essential concepts in individuals' reading comprehension,1-30440_f6e4517a-c74e-4884-92e4-b6df15fcb40b,patient monitoring,the problem faced by Large Language Models,Large-Language model (LLM),human cognitive processes,the fusion between distribution of large language models knowledge and distribution of retrieved texts
"Unsupervised meta-learning faces the challenge of effectively learning feature representations from unsupervised datasets that can be transferred to downstream tasks with limited labeled data. Existing methods may struggle with generalization to unseen tasks, highlighting the need for approaches that enhance model performance in such scenarios.",Unsupervised meta-learning,inspiration,"Background: Unsupervised meta-learning faces the challenge of effectively learning feature representations from unsupervised datasets that can be transferred to downstream tasks with limited labeled data. Existing methods may struggle with generalization to unseen tasks, highlighting the need for approaches that enhance model performance in such scenarios.
Contribution: 'Unsupervised meta-learning' inspired by ",1,a sequence modeling problem,1-8529_cf4c7775-dd6d-46c0-b47a-2e9e5e7e3824,dynamic planning in active inference,recent advances in meta learning,meta-trained models,self-supervised learning techniques,the pretext and downstream task objectives in self-supervised learning
"The challenge of efficiently generalizing an autonomous strategy for bite acquisition to a wide variety of food items necessitates a method that can adapt to novel situations without overwhelming the user. Additionally, there is a need to balance task performance with the cognitive workload imposed on users when seeking assistance during the acquisition process.",human-in-the-loop bite acquisition,inspiration,"Background: The challenge of efficiently generalizing an autonomous strategy for bite acquisition to a wide variety of food items necessitates a method that can adapt to novel situations without overwhelming the user. Additionally, there is a need to balance task performance with the cognitive workload imposed on users when seeking assistance during the acquisition process.
Contribution: 'human-in-the-loop bite acquisition' inspired by ",2,a contextual bandit framework,2-1354_1ac93972-9900-43a9-a014-caea9821fb39,a hyperplane division within the feature space,the way individuals with one functional hand prepare meals,bite transfer methods,reinforcement learning,mimicking the human workflow
"The current state-of-the-art approaches for Post-training Quantization (PTQ) often require calibration to achieve the desired accuracy, which can be a limitation in efficiently deploying Large Language Models (LLMs). Additionally, there is a need for methods that preserve privacy by eliminating the requirement for calibration or training data while maintaining model accuracy and information content.",Post-training Quantization of Large Language Models (Large Language Models),inspiration,"Background: The current state-of-the-art approaches for Post-training Quantization (PTQ) often require calibration to achieve the desired accuracy, which can be a limitation in efficiently deploying Large Language Models (LLMs). Additionally, there is a need for methods that preserve privacy by eliminating the requirement for calibration or training data while maintaining model accuracy and information content.
Contribution: 'Post-training Quantization of Large Language Models (Large Language Models)' inspired by ",2,Adaptive LASSO regression model,2-29581_8487266a-eb35-4090-9193-90e818d727f7,the computer science literature,recent advances in efficiently tuning large language models,fine-tuning of small language models (SLMs),zero-shot learning,a federated approach to the data acquisition problem
"Existing methods for transferability estimation are insufficient as they either analyze the output of pre-trained models or compare them with probe models, leading to unreliable and inefficient estimations. There is a need for a more effective approach that considers the separability and similarity of pre-trained features to enhance transferability assessments.",Transferability estimation,inspiration,"Background: Existing methods for transferability estimation are insufficient as they either analyze the output of pre-trained models or compare them with probe models, leading to unreliable and inefficient estimations. There is a need for a more effective approach that considers the separability and similarity of pre-trained features to enhance transferability assessments.
Contribution: 'Transferability estimation' inspired by ",1,kernel methods,1-369_a0696c84-1f4a-4280-87a9-58b2123875d3,creative agents,transfer learning,transfer learning,information theory,a similarity decoding problem
"The limited sampling rate of conventional optical cameras makes it difficult to obtain sufficient focus cues during the focal sweep, highlighting a challenge in accurately estimating depth from focus. This limitation necessitates the exploration of alternative methods that can provide more temporal information for focus time acquisition.",Depth from Focus,inspiration,"Background: The limited sampling rate of conventional optical cameras makes it difficult to obtain sufficient focus cues during the focal sweep, highlighting a challenge in accurately estimating depth from focus. This limitation necessitates the exploration of alternative methods that can provide more temporal information for focus time acquisition.
Contribution: 'Depth from Focus' inspired by ",2,biological vision,2-2468_95f6afb3-ed84-44ee-821f-1090b5b88c5d,a reference target image as a visual guide,depth information from a time-of-flight camera,monocular depth estimation method,light field cameras,a process of temporal disparity completion followed by continuous iterative refinements
"Existing methods for controlled paraphrase generation often require detailed parse trees or syntactic exemplars, which do not align with human-like paraphrasing behavior. Additionally, there is an inference gap where control specifications are only available during training, limiting the model's ability to operate effectively during inference.",user intent,inspiration,"Background: Existing methods for controlled paraphrase generation often require detailed parse trees or syntactic exemplars, which do not align with human-like paraphrasing behavior. Additionally, there is an inference gap where control specifications are only available during training, limiting the model's ability to operate effectively during inference.
Contribution: 'user intent' inspired by ",1,"action tokens, embedding and concatenating them with text embeddings, thus flowing together into a self-attention encoder for representation fusion",1-31210_17837f1a-230e-45c4-bd83-f4394a1c55b6,spatial priors embedded in a set of guide functions,an ensemble of a paraphrase LM for prompt (or instruction) rewriting,text paraphrasing,natural language processing techniques,a usual syntactic language model
