context,anchor,relation,query,k,positive,id,arxiv_categories,is_cross_domain,random,mpnet_zero,sciIE,gpt-4o,ours
"There is a growing concern about distinguishing between LLM-generated and human-written texts to prevent misuse, such as the dissemination of misleading information and academic dishonesty. Previous research has primarily focused on classifying text as either entirely human-written or LLM-generated, neglecting the detection of mixed texts that contain both types of content.",distinguishing between LLM-generated and human-written texts,inspiration,"Background: There is a growing concern about distinguishing between LLM-generated and human-written texts to prevent misuse, such as the dissemination of misleading information and academic dishonesty. Previous research has primarily focused on classifying text as either entirely human-written or LLM-generated, neglecting the detection of mixed texts that contain both types of content.
Contribution: 'distinguishing between LLM-generated and human-written texts' inspired by ",1,a token classification problem,1-4330_cca3fb24-9267-4e27-941e-55040f509ca5,['cs.cl'],False,Adversarial attacks against language models(LMs),an LLM that effectively processes textual information,LLM's textual representation counterparts,stylometry techniques,recent works on machine-generated text detection
"The study addresses the challenge of effectively generating AI research leaderboards by extracting specific quadruples from scholarly articles, highlighting the limitations of traditional approaches that rely on predefined taxonomies. It emphasizes the need for improved context selection to enhance the accuracy of large language models and reduce the occurrence of hallucinations in information extraction tasks.","the extraction of (Task, Dataset, Metric, Score) quadruples from scholarly articles",inspiration,"Background: The study addresses the challenge of effectively generating AI research leaderboards by extracting specific quadruples from scholarly articles, highlighting the limitations of traditional approaches that rely on predefined taxonomies. It emphasizes the need for improved context selection to enhance the accuracy of large language models and reduce the occurrence of hallucinations in information extraction tasks.
Contribution: 'the extraction of (Task, Dataset, Metric, Score) quadruples from scholarly articles' inspired by ",1,a text generation objective,1-41666_89a913b3-9f44-4ee4-80d9-4861ab8d754d,['cs.cl'],False,parallel distributed compensation,for the Automatic Term Extraction and Classification (ATE) and Classification) tasks,information extraction tasks,knowledge graph construction techniques,a standard question-answering task
"The abstract highlights issues of inconsistent conceptualization and vague expression in existing NLG quality criteria, which reduce the reliability of LLM evaluations. Additionally, it points out the confusion inherent in LLMs regarding different evaluation criteria, indicating a need for further research and improvements in LLM-based evaluation methods.",NLG evaluation,inspiration,"Background: The abstract highlights issues of inconsistent conceptualization and vague expression in existing NLG quality criteria, which reduce the reliability of LLM evaluations. Additionally, it points out the confusion inherent in LLMs regarding different evaluation criteria, indicating a need for further research and improvements in LLM-based evaluation methods.
Contribution: 'NLG evaluation' inspired by ",1,behavioral testing,1-2288_347a15a9-1b5a-49bf-92a8-a2b9d4cee10d,['cs.cl'],True,implicit feature embeddings,evaluating the quality of text generated by generative Large Language Models(LLMs),LLM-based automatic evaluation metric,human linguistic judgment,human evaluation
The alignment and coverage of LLM-based evaluations are often limited by the scope and potential bias of the evaluation prompts and criteria. This challenge necessitates a more comprehensive approach to align LLM-based evaluators with human preferences effectively.,Large language models,inspiration,"Background: The alignment and coverage of LLM-based evaluations are often limited by the scope and potential bias of the evaluation prompts and criteria. This challenge necessitates a more comprehensive approach to align LLM-based evaluators with human preferences effectively.
Contribution: 'Large language models' inspired by ",1,the evaluation mindset of human experts,1-22772_2fef663b-19c1-4b0d-b271-d94b993740b1,['cs.cl'],True,Argumentative Components and their corresponding Argumentative Relations (Argumentative Relations),evaluation of large language models,cross-lingual capabilities of LLMs,human cognitive processes,aligning Large Language Models with human preferences
Existing large language models (LLMs) underperform in legal judgment prediction due to challenges in understanding case complexities and distinguishing between similar charges. This highlights a need for improved methodologies that can effectively address these issues to enhance judicial efficiency.,Legal judgment prediction,inspiration,"Background: Existing large language models (LLMs) underperform in legal judgment prediction due to challenges in understanding case complexities and distinguishing between similar charges. This highlights a need for improved methodologies that can effectively address these issues to enhance judicial efficiency.
Contribution: 'Legal judgment prediction' inspired by ",1,human judicial reasoning,1-5953_75b9e640-b5b5-4843-b993-87357fa3b599,['cs.cl'],True,Keyphrase Recommendation,a multitask benchmark dataset for assessing the Arabic legal knowledge of Large Language Models,large-scale legal knowledge base,case-based reasoning,"the Issue, Rule, Application, Conclusion (Issue, Rule, Application, Conclusion) framework, a sequential reasoning approach used by lawyers"
