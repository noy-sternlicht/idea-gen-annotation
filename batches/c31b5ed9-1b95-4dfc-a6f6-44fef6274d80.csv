context,anchor,relation,query,k,positive,id,arxiv_categories,random,mpnet_zero,sciIE,gpt-4o,ours
"The design of existing Large Multimodal Models leads to inefficiencies due to an excessive number of tokens required for dense visual scenarios, such as high-resolution images and videos. Current token pruning and merging methods lack flexibility in balancing information density and efficiency, highlighting a need for improved representation strategies that can adapt to varying complexities of visual content.",Learned Visual Content Representation,inspiration,"Background: The design of existing Large Multimodal Models leads to inefficiencies due to an excessive number of tokens required for dense visual scenarios, such as high-resolution images and videos. Current token pruning and merging methods lack flexibility in balancing information density and efficiency, highlighting a need for improved representation strategies that can adapt to varying complexities of visual content.
Contribution: 'Learned Visual Content Representation' inspired by ",1,the concept of Matryoshka Dolls,1-28267_42e9dab5-5541-4427-8fac-63e27d0ea054,"['cs.cv', ' cs.ai', ' cs.cl', ' cs.lg']",context-aware decoding,Large Multimodal Models,multimodal representations,biological vision systems,the token-mixing technique applied in 2D images
"The use of large language models (LLMs) in customer support applications is challenged by their tendency to hallucinate, which complicates their practical implementation. This necessitates a new approach to effectively leverage LLMs while mitigating their limitations in generating reliable responses.",the language modeling task,inspiration,"Background: The use of large language models (LLMs) in customer support applications is challenged by their tendency to hallucinate, which complicates their practical implementation. This necessitates a new approach to effectively leverage LLMs while mitigating their limitations in generating reliable responses.
Contribution: 'the language modeling task' inspired by ",1,a discriminative classification task,1-17133_f28a22ed-aa09-406d-8f6e-e9c33da21483,"['cs.cl', ' cs.lg']",a self-training mechanism,large language models(LLMs),prompt-engineering-based large language models (LLMs),human conversation patterns,a direct-answer-prediction process
"There has been little exploration of the capabilities of large vision-language models when dealing with figurative meaning in images and captions, such as metaphors or humor. This gap in research highlights the need for a better understanding of how these models can generalize from literal to figurative meaning, particularly when it is present in images.",the figurative meaning understanding problem,inspiration,"Background: There has been little exploration of the capabilities of large vision-language models when dealing with figurative meaning in images and captions, such as metaphors or humor. This gap in research highlights the need for a better understanding of how these models can generalize from literal to figurative meaning, particularly when it is present in images.
Contribution: 'the figurative meaning understanding problem' inspired by ",1,an explainable visual entailment task,1-35768_0fe73cd2-ace7-4a20-a064-9b54f3e6b733,"['cs.cl', ' cs.ai', ' cs.cv']",a synthetic degradation pipeline,visual analogical reasoning in large multimodal models,fine-grained understanding of literal meaning,cognitive linguistics,a vision-language fusion problem
"Previous research has primarily relied on statistical-based features derived from EventStream logs, which, while useful, do not capture the temporal information necessary to understand fine-grained differences in learning behaviors among students. This gap highlights the need for a more effective feature representation method that incorporates time information to enhance insights into student learning activities.",operation logs and their time intervals for each student,inspiration,"Background: Previous research has primarily relied on statistical-based features derived from EventStream logs, which, while useful, do not capture the temporal information necessary to understand fine-grained differences in learning behaviors among students. This gap highlights the need for a more effective feature representation method that incorporates time information to enhance insights into student learning activities.
Contribution: 'operation logs and their time intervals for each student' inspired by ",1,a string sequence of characters,1-12405_0c94a078-64a1-47f0-bdda-1ddce0c2a94d,"['cs.cy', ' cs.ai', ' cs.cl', ' cs.lg']",hyperdimensional vector computing algebras,learning analytics,learning analytics,time-series analysis,a sequence of temporal graphs
"The auto-regressive decoding of Large Language Models (LLMs) results in significant overheads in hardware performance, particularly in terms of memory consumption and training cost, which are often overlooked in existing speculative decoding techniques. Additionally, there is a need to recover conditional dependency information for multi-token generation to improve acceptance rates for long-range predictions.",Large Language Models,inspiration,"Background: The auto-regressive decoding of Large Language Models (LLMs) results in significant overheads in hardware performance, particularly in terms of memory consumption and training cost, which are often overlooked in existing speculative decoding techniques. Additionally, there is a need to recover conditional dependency information for multi-token generation to improve acceptance rates for long-range predictions.
Contribution: 'Large Language Models' inspired by ",1,the human natural language generation process,1-38796_a6183606-5827-4750-892f-2505069e3051,"['cs.lg', ' cs.cl']",context has been well studied for learning representations,Decoder-only Large Language Models,decoder-only large language models (LLMs),recurrent neural networks,recent work that predicts the probabilities of subsequent tokens using multiple heads
