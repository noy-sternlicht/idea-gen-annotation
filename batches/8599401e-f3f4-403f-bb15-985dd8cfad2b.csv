context,anchor,relation,query,k,positive,id,arxiv_categories,is_cross_domain,random,mpnet_zero,sciIE,gpt-4o,ours
"Existing literature has predominantly focused on ingroup favoritism, often overlooking outgroup bias, which is a fundamental source of intergroup prejudice and discrimination. This gap in research highlights the need to explore how identity assignments in large language models can lead to both ingroup favoritism and outgroup bias.",artificial intelligence,inspiration,"Background: Existing literature has predominantly focused on ingroup favoritism, often overlooking outgroup bias, which is a fundamental source of intergroup prejudice and discrimination. This gap in research highlights the need to explore how identity assignments in large language models can lead to both ingroup favoritism and outgroup bias.
Contribution: 'artificial intelligence' inspired by ",1,human cognition,1-848_8cf46458-3b1a-47b0-b819-4210de88aa61,['cs.cl'],True,item's correlation and sequential information from the search system to build a heterogeneous graph for better Click-through-rate prediction in e-commerce search,modeling the intergroup bias,inter-identity discrimination,social identity theory,social philosophy
Reasoning about compositional rules is challenging because it requires multiple reasoning steps and attending to the logical relationships between elements. There is a need for effective methods to elicit rule-based reasoning in complex logical expressions.,causal language models as rule-based reasoners,inspiration,"Background: Reasoning about compositional rules is challenging because it requires multiple reasoning steps and attending to the logical relationships between elements. There is a need for effective methods to elicit rule-based reasoning in complex logical expressions.
Contribution: 'causal language models as rule-based reasoners' inspired by ",1,"the Issue, Rule, Application, Conclusion (Issue, Rule, Application, Conclusion) framework, a sequential reasoning approach used by lawyers",1-40473_92341f82-89ed-4e50-a21c-e848cddb91c1,['cs.cl'],False,unitary weights,rule-based logic,rule-based reasoners,symbolic logic systems,Pearl's structural causal models
"The propagation of social biases within large language models, inherited from diverse training datasets, presents a significant challenge in understanding and mitigating these biases. There is a necessity for tailored debiasing strategies and a deeper understanding of the complex mechanisms and pathways through which bias operates in these models.",the evolution of bias-related features in Large Language Models,inspiration,"Background: The propagation of social biases within large language models, inherited from diverse training datasets, presents a significant challenge in understanding and mitigating these biases. There is a necessity for tailored debiasing strategies and a deeper understanding of the complex mechanisms and pathways through which bias operates in these models.
Contribution: 'the evolution of bias-related features in Large Language Models' inspired by ",1,causal mediation analysis,1-710_6debd94c-e2b4-4874-a585-24876952adbb,['cs.cl'],True,a Lagrangian-mechanics-based physical model,studying biases and inherent knowledge of large language modelss,Large Language Model Bias Index (LLMBI),cultural evolution theory,the spread of rumors or influence in an online social network
"The internal mechanisms of how multimodal large language models process features from diverse domains remain unexplored, indicating a need for further investigation into the distribution of domain-specific neurons. Additionally, while current models demonstrate Visual Question Answering capability, they do not fully utilize domain-specific information, highlighting a gap in their effectiveness.",Projecting visual features into word embedding space,inspiration,"Background: The internal mechanisms of how multimodal large language models process features from diverse domains remain unexplored, indicating a need for further investigation into the distribution of domain-specific neurons. Additionally, while current models demonstrate Visual Question Answering capability, they do not fully utilize domain-specific information, highlighting a gap in their effectiveness.
Contribution: 'Projecting visual features into word embedding space' inspired by ",1,multilingual research,1-31870_974857e0-abd8-4ef1-8ef5-2ef3a634c21f,['cs.cl'],False,image-based generative AI,state-of-the-art multimodal large language models,multimodal large language model,multimodal transformers,the image-to-text mapping process by the multimodal connector
"Existing methods for early exiting in large language models require significant effort to train internal classifiers and can only achieve comparable performance at best, highlighting a need for more efficient approaches. Additionally, the high computational overhead associated with model inference presents a challenge that necessitates innovative solutions to accelerate inference while maintaining performance.",the early exiting problem,inspiration,"Background: Existing methods for early exiting in large language models require significant effort to train internal classifiers and can only achieve comparable performance at best, highlighting a need for more efficient approaches. Additionally, the high computational overhead associated with model inference presents a challenge that necessitates innovative solutions to accelerate inference while maintaining performance.
Contribution: 'the early exiting problem' inspired by ",1,a distribution prediction problem,1-7666_2a8784a6-8ba4-427a-83c8-f512ec6d752c,['cs.cl'],True,Vision-Language foundation models (VL-models),recent success of Large Language Models,few-shot capabilities of large language models,dynamic neural networks,a sequential decision-making problem
