context,anchor,relation,query,k,positive,id,random,mpnet_zero,sciIE,gpt-4o,ours
"The performance of large language models (LLMs) is heavily dependent on the input prompt, and previous works on prompt optimization often require numeric scores to assess prompt quality, which are infeasible and unreliable when interacting with a black-box LLM. Instead, obtaining preference feedback from human users is significantly easier and more reliable, highlighting a need for methodologies that can optimize prompts using this type of feedback.",prompt optimization with human feedback,inspiration,"Background: The performance of large language models (LLMs) is heavily dependent on the input prompt, and previous works on prompt optimization often require numeric scores to assess prompt quality, which are infeasible and unreliable when interacting with a black-box LLM. Instead, obtaining preference feedback from human users is significantly easier and more reliable, highlighting a need for methodologies that can optimize prompts using this type of feedback.
Contribution: 'prompt optimization with human feedback' inspired by ",1,dueling bandits,1-13583_0d12bf33-27bd-4223-aa0e-b22768f270e6,fMRI data,learning prompts using only text data derived from large language models,prompt-engineering-based large language models (LLMs),Reinforcement learning from human feedback (RLHF),learning from preference data
"The challenge of efficiently generalizing an autonomous strategy for bite acquisition to a wide variety of food items necessitates a method that can adapt to novel situations without overwhelming the user. Additionally, there is a need to balance task performance with the cognitive workload imposed on users when seeking assistance during the acquisition process.",human-in-the-loop bite acquisition,inspiration,"Background: The challenge of efficiently generalizing an autonomous strategy for bite acquisition to a wide variety of food items necessitates a method that can adapt to novel situations without overwhelming the user. Additionally, there is a need to balance task performance with the cognitive workload imposed on users when seeking assistance during the acquisition process.
Contribution: 'human-in-the-loop bite acquisition' inspired by ",1,a contextual bandit framework,1-1354_1ac93972-9900-43a9-a014-caea9821fb39,online search using an up-to-date model of the environment,active acoustic sensing for eating detection,assistive feeding task,reinforcement learning,a tool-use planning process
"Existing studies often rely on heuristic assumptions, such as assuming an exponential distribution for the temporal gaps in user consumption patterns, which may fail to capture the intricate dynamics of real-world recommender systems. This limitation can lead to sub-optimal performance in modeling repeat consumption behaviors effectively.",Recommender Systems,inspiration,"Background: Existing studies often rely on heuristic assumptions, such as assuming an exponential distribution for the temporal gaps in user consumption patterns, which may fail to capture the intricate dynamics of real-world recommender systems. This limitation can lead to sub-optimal performance in modeling repeat consumption behaviors effectively.
Contribution: 'Recommender Systems' inspired by ",1,the flexibility of neural ordinary differential equations in capturing the dynamics of complex systems,1-35259_0599a8ed-44eb-41de-9853-ae42d015944a,a precise generative modelling task,the characteristics of sequential recommender systems,long-tail user recommendations,reinforcement learning,the characteristics of sequential recommender systems
The existing approaches to time series prediction face challenges in learning variate-centric representations and risk missing essential temporal information critical for accurate forecasting. This highlights a need for a methodology that can effectively model global dependencies while retaining important correlations across both time and variate dimensions.,the input time series data,inspiration,"Background: The existing approaches to time series prediction face challenges in learning variate-centric representations and risk missing essential temporal information critical for accurate forecasting. This highlights a need for a methodology that can effectively model global dependencies while retaining important correlations across both time and variate dimensions.
Contribution: 'the input time series data' inspired by ",2,a grid,2-39990_3dced970-6063-4a9f-b874-0b8fafb8cc77,Field annotations,multivariate time series forecasting,financial time series prediction,graph neural networks,a sequence of temporal graphs
"The existing federated learning techniques encounter various obstacles, particularly in scenarios with extremely non-IID data distributions and a large number of clients. There is a need for methods that can perform competitively in these challenging settings while addressing issues related to data heterogeneity and the necessity for multiple training and aggregation rounds.",federated learning,inspiration,"Background: The existing federated learning techniques encounter various obstacles, particularly in scenarios with extremely non-IID data distributions and a large number of clients. There is a need for methods that can perform competitively in these challenging settings while addressing issues related to data heterogeneity and the necessity for multiple training and aggregation rounds.
Contribution: 'federated learning' inspired by ",1,analytic learning -- a gradient-free technique that trains neural networks with analytical solutions in one epoch,1-17545_f2cf3202-cbc7-4c7f-ad4e-588e52f552cd,an adversarial-contrastive learning objective,federated learning techniques,Federated learning algorithms,multi-task learning,federated learning paradigm
"The quantification of emergence in large language models (LLMs) has proven challenging due to the lack of a measurable definition and the difficulties in interpreting statistical estimations based on model performances. Existing methods consume significant resources and may not accurately reflect the models' intrinsic emergence, highlighting a need for a more effective and interpretable approach to estimate emergence.","the ""intelligent"" behaviors of LLMs",inspiration,"Background: The quantification of emergence in large language models (LLMs) has proven challenging due to the lack of a measurable definition and the difficulties in interpreting statistical estimations based on model performances. Existing methods consume significant resources and may not accurately reflect the models' intrinsic emergence, highlighting a need for a more effective and interpretable approach to estimate emergence.
Contribution: 'the ""intelligent"" behaviors of LLMs' inspired by ",2,emergentism in dynamics,2-13716_8b0b1d3d-7343-4307-a2e2-1361c3f98b56,robots,the operational mechanisms of Large language models,generative power of Large Language Models,the human cognitive process,psychometrically inspired framework
"The effectiveness of query-based end-to-end instance segmentation methods diminishes significantly when confronted with limited training data, as they rely on substantial data volumes to effectively train the pivotal queries and kernels necessary for acquiring localization and shape priors. This limitation highlights the need for improved methods that can enhance performance in low-data regimes.",unsupervised pre-training in low-data regimes,inspiration,"Background: The effectiveness of query-based end-to-end instance segmentation methods diminishes significantly when confronted with limited training data, as they rely on substantial data volumes to effectively train the pivotal queries and kernels necessary for acquiring localization and shape priors. This limitation highlights the need for improved methods that can enhance performance in low-data regimes.
Contribution: 'unsupervised pre-training in low-data regimes' inspired by ",1,the recently successful prompting technique,1-21054_a9a52e87-b684-470b-a6c5-28cb7ae9414b,the 'Bias Considerations in Bilingual Natural Language Processing' report by Statistics Canada,instance segmentation,unsupervised instance segmentation,contrastive learning,self-supervised learning used for pre-training
"Existing edge-aware graph neural networks and language models often fail to fully capture the contextualized semantics on edges and the graph topology, which is particularly problematic in link prediction tasks that require a comprehensive understanding of the relationships between nodes. This highlights a need for improved methodologies that can effectively integrate both semantic and topological information in textual-edge graphs.",summarize neighborhood information between node pairs,inspiration,"Background: Existing edge-aware graph neural networks and language models often fail to fully capture the contextualized semantics on edges and the graph topology, which is particularly problematic in link prediction tasks that require a comprehensive understanding of the relationships between nodes. This highlights a need for improved methodologies that can effectively integrate both semantic and topological information in textual-edge graphs.
Contribution: 'summarize neighborhood information between node pairs' inspired by ",2,a human-written document,2-22490_65d4bb94-160c-4eeb-955e-2204a958470e,the Convolutional Neural Networks model,Link prediction in graph representation learning,latent graph neural network,graph attention networks,"nodes and edges are robot joints and links, respectively"
"Identifying and including character identities in story descriptions is crucial for story understanding, yet previous work has largely overlooked this aspect, often generating captions with anonymized names. Additionally, there is a challenge in evaluating id-aware captioning due to the lack of a metric that captures subtle differences between person identities.",id-aware captioning,inspiration,"Background: Identifying and including character identities in story descriptions is crucial for story understanding, yet previous work has largely overlooked this aspect, often generating captions with anonymized names. Additionally, there is a challenge in evaluating id-aware captioning due to the lack of a metric that captures subtle differences between person identities.
Contribution: 'id-aware captioning' inspired by ",2,a fill-in-the-blanks task,2-31218_c9f2e1c5-fdb2-4296-b2ae-c6b3f8a2564f,Inferring 3D human motion,a captioning system,brief character descriptions,named entity recognition,human identity verification methods
"There is a lack of principled understanding regarding the design of frames in the context of achieving symmetries in neural networks. Existing methods do not fully explore the connection between frames and canonical forms, which limits the ability to compare frame complexity and determine optimality effectively.",neural networks,inspiration,"Background: There is a lack of principled understanding regarding the design of frames in the context of achieving symmetries in neural networks. Existing methods do not fully explore the connection between frames and canonical forms, which limits the ability to compare frame complexity and determine optimality effectively.
Contribution: 'neural networks' inspired by ",1,canonization is a classic approach for attaining invariance by mapping inputs to their canonical forms,1-16943_93f8fa68-722c-48aa-b829-040eeeb23674,a dual-channel encoder,equivariant neural networks,SIM(3)-equivariant neural network architectures,geometric deep learning,canonization is a classic approach for attaining invariance by mapping inputs to their canonical forms
