context,anchor,relation,query,k,positive,id,ours,random,mpnet_zero,sciIE,gpt-4o
"Current Dynamic Facial Expression Recognition methods often overlook the influence of scene context, focusing solely on facial information and leading to discrepancies between human annotators' emotional understanding and model outputs. This limitation highlights the need for approaches that better integrate environmental cues and body language to align with human cognitive processes in emotion recognition.",Dynamic Facial Expression Recognition,inspiration,"Background: Current Dynamic Facial Expression Recognition methods often overlook the influence of scene context, focusing solely on facial information and leading to discrepancies between human annotators' emotional understanding and model outputs. This limitation highlights the need for approaches that better integrate environmental cues and body language to align with human cognitive processes in emotion recognition.
Contribution: 'Dynamic Facial Expression Recognition' inspired by ",1,the human cognitive paradigm of emotions,1-37558_d5d3b232-6290-4793-aa81-e5bbaa631151,"For instance, multi-modal emotional context (such as voice color, affective text, body pose, etc.) can prompt people to perceive emotional expressions in objectively neutral faces",causal,dynamic facial expression recognition data,highly dynamic and subtle facial expressions,multimodal learning
"The study addresses the challenges of local and global consistency in sketch colourisation, as well as the limitations of manual colour assignments and textual prompts. It also highlights the need for a method that balances precision and convenience while being fast and training-free for practical use in creative applications.",a novel approach to sketch colourisation,inspiration,"Background: The study addresses the challenges of local and global consistency in sketch colourisation, as well as the limitations of manual colour assignments and textual prompts. It also highlights the need for a method that balances precision and convenience while being fast and training-free for practical use in creative applications.
Contribution: 'a novel approach to sketch colourisation' inspired by ",1,the universal childhood activity of colouring and its professional applications in design and story-boarding,1-38011_12cd838e-bb23-4975-b589-d8044a7668ec,Crayon Prompt as a new visual prompt tuning scheme based on panoptic color maps,Bootstrapping Language-Image Pre-training,the sketch analysis task,human sketch understanding,neural style transfer
"Current multi-modal large language models face challenges in detailed multi-modal understanding, complex task comprehension, and reasoning over multi-modal information. There is a need for improved performance in complex visual reasoning tasks, as existing models have inherent limitations in these areas.",Multi-modal Critical Thinking Agent,inspiration,"Background: Current multi-modal large language models face challenges in detailed multi-modal understanding, complex task comprehension, and reasoning over multi-modal information. There is a need for improved performance in complex visual reasoning tasks, as existing models have inherent limitations in these areas.
Contribution: 'Multi-modal Critical Thinking Agent' inspired by ",2,human cognitive processes and critical thinking,2-30926_9fa60d50-fe7e-4906-92b7-29db52481188,a model capable of reasoning over long multi-modal sequences,CNNs for accurate condition injection,recent success of leveraging large language models for visual reasoning,multimodal comprehension,cognitive neuroscience
